<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>pytorch-inference: /Users/Aman/code/pytorch-inference/include/layers.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">pytorch-inference
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('layers_8hpp_source.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">layers.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="layers_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Created by Aman LaChapelle on 5/19/17.</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">// pytorch_inference</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">// Copyright (c) 2017 Aman LaChapelle</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">// Full license at pytorch_inference/LICENSE.txt</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">    This program is free software: you can redistribute it and/or modify</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment">    it under the terms of the GNU General Public License as published by</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">    the Free Software Foundation, either version 3 of the License, or</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment">    (at your option) any later version.</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">    This program is distributed in the hope that it will be useful,</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">    but WITHOUT ANY WARRANTY; without even the implied warranty of</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment">    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment">    GNU General Public License for more details.</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment">    You should have received a copy of the GNU General Public License</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment">    along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#ifndef PYTORCH_INFERENCE_LAYERS_HPP</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="preprocessor">#define PYTORCH_INFERENCE_LAYERS_HPP</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &lt;arrayfire.h&gt;</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="ops_8hpp.html">ops.hpp</a>&quot;</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="utils_8hpp.html">utils.hpp</a>&quot;</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="py__object_8hpp.html">py_object.hpp</a>&quot;</span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacepytorch.html">pytorch</a> {</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196">   39</a></span>&#160;  <span class="keyword">enum</span> <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196">dims</a> {</div><div class="line"><a name="l00040"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a72642ee422e2c907c36ca4762478cb3d">   40</a></span>&#160;    <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a72642ee422e2c907c36ca4762478cb3d">n</a> = 3,</div><div class="line"><a name="l00041"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a73a50f78ad527d77d9f062bf071de1b5">   41</a></span>&#160;    <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a73a50f78ad527d77d9f062bf071de1b5">k</a> = 2,</div><div class="line"><a name="l00042"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a1f250f3998835bb50ff8608dead82418">   42</a></span>&#160;    <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a1f250f3998835bb50ff8608dead82418">h</a> = 0,</div><div class="line"><a name="l00043"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a15d37568bf28ad3bce066ae5692e91de">   43</a></span>&#160;    <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a15d37568bf28ad3bce066ae5692e91de">w</a> = 1</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;  };</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;</div><div class="line"><a name="l00055"></a><span class="lineno"><a class="line" href="classpytorch_1_1_layer.html">   55</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;    <span class="keyword">inline</span> <span class="keyword">virtual</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_layer.html#a1abb45857b18f70a9a95ae16a69f968d">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input) = 0;</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    <span class="keyword">inline</span> <span class="keyword">virtual</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_layer.html#a7a766ac20be5e818e497e6f2f05a2c8d">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input) = 0;</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;  };</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;</div><div class="line"><a name="l00077"></a><span class="lineno"><a class="line" href="classpytorch_1_1_skip.html">   77</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_skip.html">Skip</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00084"></a><span class="lineno"><a class="line" href="classpytorch_1_1_skip.html#ab3833af82d8d8b7579b2515d6e06e5ce">   84</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_skip.html#ab3833af82d8d8b7579b2515d6e06e5ce">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;      <span class="keywordflow">return</span> input;</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    }</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;</div><div class="line"><a name="l00093"></a><span class="lineno"><a class="line" href="classpytorch_1_1_skip.html#a968c864ee798307240bd9ea3d17156c3">   93</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_skip.html#a968c864ee798307240bd9ea3d17156c3">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;      <span class="keywordflow">return</span> input;</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;    }</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;  };</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;</div><div class="line"><a name="l00106"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html">  106</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_conv2d.html">Conv2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    af::array filters;</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    af::array bias;</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;    <a class="code" href="structpytorch_1_1conv__params__t.html">conv_params_t</a> params;</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;    <a class="code" href="classpycpp_1_1py__object.html">pycpp::py_object</a> utils;</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;    <span class="keywordtype">bool</span> has_bias;</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00122"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a2d4e756090fe5a4c9637ad97959d7614">  122</a></span>&#160;    <a class="code" href="classpytorch_1_1_conv2d.html#a2d4e756090fe5a4c9637ad97959d7614">Conv2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">conv_params_t</a> &amp;params,</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;           <span class="keyword">const</span> af::array &amp;filters,</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;           <span class="keyword">const</span> af::array &amp;bias) : params(params), filters(filters), bias(bias) { }</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;</div><div class="line"><a name="l00137"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#ac596c3c020ec5ac7e324e6d32a7539bc">  137</a></span>&#160;    <a class="code" href="classpytorch_1_1_conv2d.html#ac596c3c020ec5ac7e324e6d32a7539bc">Conv2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">conv_params_t</a> &amp;params,</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;           <span class="keyword">const</span> std::string &amp;filters_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;           <span class="keyword">const</span> std::vector&lt;int&gt; &amp;filt_dims = {},</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;           <span class="keyword">const</span> <span class="keywordtype">bool</span> &amp;has_bias = <span class="keyword">false</span>,</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;           <span class="keyword">const</span> std::string &amp;bias_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;           <span class="keyword">const</span> std::vector&lt;int&gt; &amp;bias_dims = {},</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;           <span class="keyword">const</span> std::string &amp;python_home = <span class="stringliteral">&quot;../scripts&quot;</span>) : params(params),</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;                                                            utils(<span class="stringliteral">&quot;utils&quot;</span>, python_home),</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;                                                            has_bias(has_bias) {</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;      <span class="keywordflow">if</span> (!filters_filename.empty()){</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        this-&gt;add_filters(filters_filename, filt_dims);</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;      }</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;      <span class="keywordflow">if</span> (!bias_filename.empty() &amp;&amp; has_bias){</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;        this-&gt;add_bias(bias_filename, bias_dims);</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;      }</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    }</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;</div><div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a625e155c4c0e9aafa899ddcba2ce5fc6">  162</a></span>&#160;    <a class="code" href="classpytorch_1_1_conv2d.html#a625e155c4c0e9aafa899ddcba2ce5fc6">Conv2d</a>(<span class="keyword">const</span> <a class="code" href="classpytorch_1_1_conv2d.html">Conv2d</a> &amp;other){</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;      filters = other.filters;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;      bias = other.bias;</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;      params = other.params;</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;    }</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;</div><div class="line"><a name="l00171"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a5e7eb9604dbc94ca62edd04ec8944faf">  171</a></span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classpytorch_1_1_conv2d.html#a5e7eb9604dbc94ca62edd04ec8944faf">~Conv2d</a>() {}</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;</div><div class="line"><a name="l00180"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#ac7173111158536b89905c320e53cc4b8">  180</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_conv2d.html#ac7173111158536b89905c320e53cc4b8">add_filters</a>(const::std::string &amp;filters_filename,</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;                            <span class="keyword">const</span> std::vector&lt;int&gt; &amp;filt_dims){</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;      assert(filt_dims.size() &gt; 0);</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;      PyObject *filts = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(filters_filename)});</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;      assert(filts);</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;      filters = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(filts), filt_dims.size(), filt_dims);</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;    }</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;</div><div class="line"><a name="l00195"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#afeb76a74cb0f632466bc52dd12829ca5">  195</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_conv2d.html#afeb76a74cb0f632466bc52dd12829ca5">add_bias</a>(<span class="keyword">const</span> std::string &amp;bias_filename,</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;                         <span class="keyword">const</span> std::vector&lt;int&gt; &amp;bias_dims){</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;      assert(bias_dims.size() &gt; 0);</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;      PyObject *bs = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(bias_filename)});</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;      assert(bs);</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;      bias = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(bs), bias_dims.size(), bias_dims);</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;    }</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;</div><div class="line"><a name="l00210"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a953a1db977476c1b7d963459a63b9034">  210</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_conv2d.html#a953a1db977476c1b7d963459a63b9034">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a94ec836f5c6229b0b05a2d5d0c083861">conv2d</a>(params, input[0], filters, bias, has_bias)};</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;    }</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;</div><div class="line"><a name="l00221"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#ad59f5c6c9fd3a6a238cfa50fa94e4019">  221</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_conv2d.html#ad59f5c6c9fd3a6a238cfa50fa94e4019">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a94ec836f5c6229b0b05a2d5d0c083861">conv2d</a>(params, input[0], filters, bias, has_bias)};</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;    }</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;  };</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;</div><div class="line"><a name="l00236"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html">  236</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_max_pool2d.html">MaxPool2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;    <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> params;</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;    af::array indices;</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00247"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a8c601902ed93f0afa8ab61e62110f19f">  247</a></span>&#160;    <a class="code" href="classpytorch_1_1_max_pool2d.html#a8c601902ed93f0afa8ab61e62110f19f">MaxPool2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> &amp;params) : params(params) {}</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;</div><div class="line"><a name="l00255"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a5f2ea435fea042c0677ecd665de1405b">  255</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_max_pool2d.html#a5f2ea435fea042c0677ecd665de1405b">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#aacf5782da70434cc8657a5ff4c612fc5">pytorch::maxpool</a>(params, input[0], indices)};</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;    }</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;</div><div class="line"><a name="l00265"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a6849f3a4850596f32f05b51273ea4eb3">  265</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_max_pool2d.html#a6849f3a4850596f32f05b51273ea4eb3">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#aacf5782da70434cc8657a5ff4c612fc5">pytorch::maxpool</a>(params, input[0], indices)};</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;    }</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;  };</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;</div><div class="line"><a name="l00278"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html">  278</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_avg_pool2d.html">AvgPool2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;    <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> params;</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00288"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html#ad23e05cd109aaa2ddeaf132b0e5cc1f8">  288</a></span>&#160;    <a class="code" href="classpytorch_1_1_avg_pool2d.html#ad23e05cd109aaa2ddeaf132b0e5cc1f8">AvgPool2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> &amp;params) : params(params) {}</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;</div><div class="line"><a name="l00296"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html#a1904e62fdaee1476b737a364b5156be7">  296</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_avg_pool2d.html#a1904e62fdaee1476b737a364b5156be7">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a78a38423eda0d20c5b3c61c69a0ce8c4">pytorch::avgpool</a>(params, input[0])};</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;    }</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;</div><div class="line"><a name="l00306"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html#a6a08e267be98ce762c062052cb9d046b">  306</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_avg_pool2d.html#a6a08e267be98ce762c062052cb9d046b">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a78a38423eda0d20c5b3c61c69a0ce8c4">pytorch::avgpool</a>(params, input[0])};</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    }</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;  };</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;</div><div class="line"><a name="l00319"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html">  319</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_batch_norm2d.html">BatchNorm2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;    af::array gamma;</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;    af::array beta;</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;    af::array running_mean;</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;    af::array running_var;</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;    <span class="keywordtype">float</span> epsilon;</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;    <a class="code" href="classpycpp_1_1py__object.html">pycpp::py_object</a> utils;</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00337"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#acad1a59f2edc4a810ff46458f4da8c82">  337</a></span>&#160;    <a class="code" href="classpytorch_1_1_batch_norm2d.html#acad1a59f2edc4a810ff46458f4da8c82">BatchNorm2d</a>(<span class="keyword">const</span> af::array &amp;gamma,</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;                <span class="keyword">const</span> af::array &amp;beta,</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;running_mean,</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;running_var,</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;epsilon = 1e-5) : gamma(gamma), beta(beta),</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;                                             running_mean(running_mean), running_var(running_var),</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;                                             epsilon(epsilon) {}</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;</div><div class="line"><a name="l00359"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a910802963973f5d64fb6d281635a1035">  359</a></span>&#160;    <a class="code" href="classpytorch_1_1_batch_norm2d.html#a910802963973f5d64fb6d281635a1035">BatchNorm2d</a>(<span class="keyword">const</span> std::string &amp;gamma_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;                <span class="keyword">const</span> std::vector&lt;int&gt; &amp;gamma_dims = {},</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;                <span class="keyword">const</span> std::string &amp;beta_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;                <span class="keyword">const</span> std::vector&lt;int&gt; &amp;beta_dims = {},</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;                <span class="keyword">const</span> std::string &amp;running_mean_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;                <span class="keyword">const</span> std::vector&lt;int&gt; &amp;running_mean_dims = {},</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;                <span class="keyword">const</span> std::string &amp;running_var_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;                <span class="keyword">const</span> std::vector&lt;int&gt; &amp;running_var_dims = {},</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;epsilon = 1e-5,</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;                <span class="keyword">const</span> std::string &amp;python_home = <span class="stringliteral">&quot;../scripts&quot;</span>) : utils(<span class="stringliteral">&quot;utils&quot;</span>, python_home), epsilon(epsilon){</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;      <span class="keywordflow">if</span> (!gamma_filename.empty()){</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;        this-&gt;add_gamma(gamma_filename, gamma_dims);</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;      }</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;      <span class="keywordflow">if</span> (!beta_filename.empty()){</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;        this-&gt;add_beta(beta_filename, beta_dims);</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;      }</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;      <span class="keywordflow">if</span> (!running_mean_filename.empty()){</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;        this-&gt;add_running_mean(running_mean_filename, running_mean_dims);</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;      }</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;      <span class="keywordflow">if</span> (!running_var_filename.empty()){</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;        this-&gt;add_running_var(running_var_filename, running_var_dims);</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;      }</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;    }</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;</div><div class="line"><a name="l00391"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#af29892810fccc85d2bc202c16c5d49fe">  391</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#af29892810fccc85d2bc202c16c5d49fe">add_gamma</a>(<span class="keyword">const</span> std::string &amp;gamma_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;                          <span class="keyword">const</span> std::vector&lt;int&gt; &amp;gamma_dims = {}){</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;      assert(gamma_dims.size() &gt; 0);</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;      PyObject *g = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(gamma_filename)});</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;      assert(g);</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;      gamma = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(g), gamma_dims.size(), gamma_dims);</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;    }</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;</div><div class="line"><a name="l00405"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a54664c298098621bc625e899c96f7af6">  405</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#a54664c298098621bc625e899c96f7af6">add_beta</a>(<span class="keyword">const</span> std::string &amp;beta_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;                          <span class="keyword">const</span> std::vector&lt;int&gt; &amp;beta_dims = {}){</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;      assert(beta_dims.size() &gt; 0);</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;      PyObject *b = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(beta_filename)});</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;      assert(b);</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;      beta = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(b), beta_dims.size(), beta_dims);</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;    }</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;</div><div class="line"><a name="l00419"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a44601eef2233bbf8cb6da963bcf1520e">  419</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#a44601eef2233bbf8cb6da963bcf1520e">add_running_mean</a>(<span class="keyword">const</span> std::string &amp;running_mean_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;                          <span class="keyword">const</span> std::vector&lt;int&gt; &amp;running_mean_dims = {}){</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;      assert(running_mean_dims.size() &gt; 0);</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;      PyObject *rm = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(running_mean_filename)});</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;      assert(rm);</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;      running_mean = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(rm), running_mean_dims.size(), running_mean_dims);</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;    }</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;</div><div class="line"><a name="l00433"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a1816381a3443fc87ee9b25efd0cfe6e3">  433</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#a1816381a3443fc87ee9b25efd0cfe6e3">add_running_var</a>(<span class="keyword">const</span> std::string &amp;running_var_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;                                 <span class="keyword">const</span> std::vector&lt;int&gt; &amp;running_var_dims = {}){</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;      assert(running_var_dims.size() &gt; 0);</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;      PyObject *rv = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(running_var_filename)});</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;      assert(rv);</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;      running_var = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(rv), running_var_dims.size(), running_var_dims);</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;    }</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;</div><div class="line"><a name="l00447"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a708c9fbeed102fe07577f4d9321b2261">  447</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_batch_norm2d.html#a708c9fbeed102fe07577f4d9321b2261">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ae865095aad032ac1ea9516ae5361e0ab">batchnorm2d</a>(gamma, beta, running_mean, running_var, epsilon, input[0])};</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;    }</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;</div><div class="line"><a name="l00457"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#ab8a0e1cbc627b47c87a8cc5951b55e25">  457</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_batch_norm2d.html#ab8a0e1cbc627b47c87a8cc5951b55e25">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ae865095aad032ac1ea9516ae5361e0ab">batchnorm2d</a>(gamma, beta, running_mean, running_var, epsilon, input[0])};</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;    }</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;  };</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;</div><div class="line"><a name="l00471"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html">  471</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_linear.html">Linear</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;    af::array weights;</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;    af::array bias;</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;    <a class="code" href="classpycpp_1_1py__object.html">pycpp::py_object</a> utils;</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;    <span class="keywordtype">bool</span> has_bias;</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00485"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a47740884c0ce199daecd9958bd6b6ca3">  485</a></span>&#160;    <a class="code" href="classpytorch_1_1_linear.html#a47740884c0ce199daecd9958bd6b6ca3">Linear</a>(<span class="keyword">const</span> af::array &amp;weights,</div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;           <span class="keyword">const</span> af::array &amp;bias) : weights(weights), bias(bias) { }</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;</div><div class="line"><a name="l00497"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#ad061ae2fec18baa95cc7b9b854b57f92">  497</a></span>&#160;    <a class="code" href="classpytorch_1_1_linear.html#ad061ae2fec18baa95cc7b9b854b57f92">Linear</a>(<span class="keyword">const</span> std::string &amp;weights_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;           <span class="keyword">const</span> std::vector&lt;int&gt; &amp;weights_dims = {},</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;           <span class="keyword">const</span> <span class="keywordtype">bool</span> has_bias = <span class="keyword">false</span>,</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;           <span class="keyword">const</span> std::string &amp;bias_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;           <span class="keyword">const</span> std::vector&lt;int&gt; &amp;bias_dims = {},</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;           <span class="keyword">const</span> std::string &amp;python_home = <span class="stringliteral">&quot;../scripts&quot;</span>) : utils(<span class="stringliteral">&quot;utils&quot;</span>, python_home), has_bias(has_bias) {</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;      <span class="keywordflow">if</span> (!weights_filename.empty()){</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;        this-&gt;add_weights(weights_filename, weights_dims);</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;      }</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;      <span class="keywordflow">if</span> (!bias_filename.empty() &amp;&amp; has_bias){</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;        this-&gt;add_bias(bias_filename, bias_dims);</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;      }</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;    }</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;</div><div class="line"><a name="l00517"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#ac8bbc9c901cda2e77ac60abccf4de372">  517</a></span>&#160;    <a class="code" href="classpytorch_1_1_linear.html#ac8bbc9c901cda2e77ac60abccf4de372">Linear</a>(<span class="keyword">const</span> <a class="code" href="classpytorch_1_1_linear.html">Linear</a> &amp;other){</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;      weights = other.weights;</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;      bias = other.bias;</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;    }</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;</div><div class="line"><a name="l00525"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a2b0abcb252baef05e13f648df24af1cf">  525</a></span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classpytorch_1_1_linear.html#a2b0abcb252baef05e13f648df24af1cf">~Linear</a>() {}</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;</div><div class="line"><a name="l00534"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a8cbffb226f756dfabc3fcbb80c075cef">  534</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_linear.html#a8cbffb226f756dfabc3fcbb80c075cef">add_weights</a>(<span class="keyword">const</span> std::string &amp;weights_filename,</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;                            <span class="keyword">const</span> std::vector&lt;int&gt; &amp;weights_dims){</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;      assert(weights_dims.size() &gt; 0);</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;      PyObject *ws = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(weights_filename)});</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;      assert(ws);</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;      weights = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(ws), weights_dims.size(), weights_dims);</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;    }</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;</div><div class="line"><a name="l00549"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a4db382b11a3f91778797a6e940692d86">  549</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_linear.html#a4db382b11a3f91778797a6e940692d86">add_bias</a>(<span class="keyword">const</span> std::string &amp;bias_filename,</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;                         <span class="keyword">const</span> std::vector&lt;int&gt; &amp;bias_dims){</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;      assert(bias_dims.size() &gt; 0);</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;      this-&gt;has_bias = <span class="keyword">true</span>;</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;      PyObject *bs = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(bias_filename)});</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;      assert(bs);</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;      bias = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(bs), bias_dims.size(), bias_dims);</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;    }</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;</div><div class="line"><a name="l00562"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a850c81192d2f73e96f42700b94091a57">  562</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_linear.html#a850c81192d2f73e96f42700b94091a57">set_has_bias</a>(<span class="keywordtype">bool</span> has_bias){</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;      this-&gt;has_bias = has_bias;</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;    }</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;</div><div class="line"><a name="l00573"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a0b0318a61558f674bff2be8410da1fb5">  573</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_linear.html#a0b0318a61558f674bff2be8410da1fb5">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ad49eda1612a5d32ca493c4980741542e">linear</a>(input[0], weights, bias, this-&gt;has_bias)};</div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;    }</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;</div><div class="line"><a name="l00584"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a6d86c19268604c3c35a7958bb55d0329">  584</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_linear.html#a6d86c19268604c3c35a7958bb55d0329">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ad49eda1612a5d32ca493c4980741542e">linear</a>(input[0], weights, bias, this-&gt;has_bias)};</div><div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;    }</div><div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;</div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;  };</div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;</div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;  <span class="comment">/* Branch - tested */</span></div><div class="line"><a name="l00591"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html">  591</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_branch.html">Branch</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;    <span class="keywordtype">int</span> copies;</div><div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00595"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#a20f7615a9da65d34b247ec79a801c06e">  595</a></span>&#160;    <a class="code" href="classpytorch_1_1_branch.html#a20f7615a9da65d34b247ec79a801c06e">Branch</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;copies) : copies(copies){}</div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;</div><div class="line"><a name="l00597"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#af70ee99c631a3c21d87ba0460130a437">  597</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_branch.html#af70ee99c631a3c21d87ba0460130a437">get_copies</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;      <span class="keywordflow">return</span> copies;</div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;    }</div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;</div><div class="line"><a name="l00601"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#ae0d6f620eab11534bb3262580c571c8f">  601</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_branch.html#ae0d6f620eab11534bb3262580c571c8f">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#aa1b0dc2ffe07685855199e859712f0a3">pytorch::copy_branch</a>(input[0], copies);</div><div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;    }</div><div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;</div><div class="line"><a name="l00605"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#a56760a37afd47d7efe851abd51b33568">  605</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_branch.html#a56760a37afd47d7efe851abd51b33568">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#aa1b0dc2ffe07685855199e859712f0a3">pytorch::copy_branch</a>(input[0], copies);</div><div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;    }</div><div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;  };</div><div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;</div><div class="line"><a name="l00610"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html">  610</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_slice2.html">Slice2</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;    <span class="keywordtype">int</span> dim;</div><div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00614"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#a2704991f0818c418d24408d7360f9d68">  614</a></span>&#160;    <a class="code" href="classpytorch_1_1_slice2.html#a2704991f0818c418d24408d7360f9d68">Slice2</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;</div><div class="line"><a name="l00616"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#aaa119a9771aaea730dd58ac6e45e8167">  616</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice2.html#aaa119a9771aaea730dd58ac6e45e8167">get_dim</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;      <span class="keywordflow">return</span> dim;</div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;    }</div><div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;</div><div class="line"><a name="l00620"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#aed74425320b96a734e7afcc1be2ac817">  620</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice2.html#aed74425320b96a734e7afcc1be2ac817">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 2, dim);</div><div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;    }</div><div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;</div><div class="line"><a name="l00624"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#abcf999345ff5e740f379e3bb9fe93e9e">  624</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice2.html#abcf999345ff5e740f379e3bb9fe93e9e">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 2, dim);</div><div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;    }</div><div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;</div><div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;  };</div><div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;</div><div class="line"><a name="l00630"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html">  630</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_slice3.html">Slice3</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;    <span class="keywordtype">int</span> dim;</div><div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00634"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#ab397c5ffb4526d2cd48c7ea64abc56b7">  634</a></span>&#160;    <a class="code" href="classpytorch_1_1_slice3.html#ab397c5ffb4526d2cd48c7ea64abc56b7">Slice3</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;</div><div class="line"><a name="l00636"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#a53fbbf80acc37d0d12520f583158461e">  636</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice3.html#a53fbbf80acc37d0d12520f583158461e">get_dim</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;      <span class="keywordflow">return</span> dim;</div><div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;    }</div><div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;</div><div class="line"><a name="l00640"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#af1a75e7f8473d605787c09320c51d63d">  640</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice3.html#af1a75e7f8473d605787c09320c51d63d">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 3, dim);</div><div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;    }</div><div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;</div><div class="line"><a name="l00644"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#a7405226a4261a588170c692ee7325cd8">  644</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice3.html#a7405226a4261a588170c692ee7325cd8">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 3, dim);</div><div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;    }</div><div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;</div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;  };</div><div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;</div><div class="line"><a name="l00650"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html">  650</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_slice4.html">Slice4</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;    <span class="keywordtype">int</span> dim;</div><div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00654"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#a7c4b6e3a751b69ed1aaf13801aa989c0">  654</a></span>&#160;    <a class="code" href="classpytorch_1_1_slice4.html#a7c4b6e3a751b69ed1aaf13801aa989c0">Slice4</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;</div><div class="line"><a name="l00656"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#a227cb3c33ab5c5752bbe365943660bf8">  656</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice4.html#a227cb3c33ab5c5752bbe365943660bf8">get_dim</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;      <span class="keywordflow">return</span> dim;</div><div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;    }</div><div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;</div><div class="line"><a name="l00660"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#a882cce34197fcb801aae899b3d7b6a91">  660</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice4.html#a882cce34197fcb801aae899b3d7b6a91">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 4, dim);</div><div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;    }</div><div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;</div><div class="line"><a name="l00664"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#a036ece17af42590a42f38e50633072de">  664</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice4.html#a036ece17af42590a42f38e50633072de">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 4, dim);</div><div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;    }</div><div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;</div><div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;  };</div><div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;</div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;  <span class="comment">/* Concat2 - tested */</span></div><div class="line"><a name="l00671"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html">  671</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_concat2.html">Concat2</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;    <span class="keywordtype">int</span> dim;</div><div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00674"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html#a4295d2772036dd4c52c68cf4cc533f9c">  674</a></span>&#160;    <a class="code" href="classpytorch_1_1_concat2.html#a4295d2772036dd4c52c68cf4cc533f9c">Concat2</a> (<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;</div><div class="line"><a name="l00676"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html#a6f45f28982b7a61093026c6715dfa9b5">  676</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat2.html#a6f45f28982b7a61093026c6715dfa9b5">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#af79090de8fcb96630036887e5f7b8ea7">pytorch::cat2</a>(input[0], input[1], dim)};</div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;    }</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;</div><div class="line"><a name="l00680"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html#ab7a24c04cf459171cd75876ee73032d0">  680</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat2.html#ab7a24c04cf459171cd75876ee73032d0">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#af79090de8fcb96630036887e5f7b8ea7">pytorch::cat2</a>(input[0], input[1], dim)};</div><div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;    }</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;  };</div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;</div><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;  <span class="comment">/* Concat3 - tested */</span></div><div class="line"><a name="l00686"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html">  686</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_concat3.html">Concat3</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;    <span class="keywordtype">int</span> dim;</div><div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00689"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html#afca3a26b9eb7824646e34ea0071331ad">  689</a></span>&#160;    <a class="code" href="classpytorch_1_1_concat3.html#afca3a26b9eb7824646e34ea0071331ad">Concat3</a> (<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;</div><div class="line"><a name="l00691"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html#a3bea4ffd404197583dd5adecbc94e2f0">  691</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat3.html#a3bea4ffd404197583dd5adecbc94e2f0">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a9243e92d218fdf3718ab963e4005988e">pytorch::cat3</a>(input[0], input[1], input[2], dim)};</div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;    }</div><div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;</div><div class="line"><a name="l00695"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html#a57470086b64b3b7ff5c50e2e3cd8cebf">  695</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat3.html#a57470086b64b3b7ff5c50e2e3cd8cebf">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a9243e92d218fdf3718ab963e4005988e">pytorch::cat3</a>(input[0], input[1], input[2], dim)};</div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;    }</div><div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;  };</div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;</div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;  <span class="comment">/* Concat4 - higher is not supported by arrayfire - tested */</span></div><div class="line"><a name="l00701"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html">  701</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_concat4.html">Concat4</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;    <span class="keywordtype">int</span> dim;</div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00704"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html#af9ff578363eb1d53202e0614bc3c6aa1">  704</a></span>&#160;    <a class="code" href="classpytorch_1_1_concat4.html#af9ff578363eb1d53202e0614bc3c6aa1">Concat4</a> (<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;</div><div class="line"><a name="l00706"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html#ad8115f840f7937f47849357f8f05a336">  706</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat4.html#ad8115f840f7937f47849357f8f05a336">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ac48fbbcee5e49075953d6b3117eaa329">pytorch::cat4</a>(input[0], input[1], input[2], input[3], dim)};</div><div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;    }</div><div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;</div><div class="line"><a name="l00710"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html#aad8088bbad685a8d07ea11b2fa72d2ff">  710</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat4.html#aad8088bbad685a8d07ea11b2fa72d2ff">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ac48fbbcee5e49075953d6b3117eaa329">pytorch::cat4</a>(input[0], input[1], input[2], input[3], dim)};</div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;    }</div><div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;  };</div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;</div><div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;  <span class="comment">/* Sigmoid - tested */</span></div><div class="line"><a name="l00716"></a><span class="lineno"><a class="line" href="classpytorch_1_1_sigmoid.html">  716</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_sigmoid.html">Sigmoid</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00718"></a><span class="lineno"><a class="line" href="classpytorch_1_1_sigmoid.html#a8e7e598171e919a5dd3dfd54ad38dbdc">  718</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_sigmoid.html#a8e7e598171e919a5dd3dfd54ad38dbdc">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ac61be684e3426c6f8c53dc794ccf3a70">pytorch::sigmoid</a>(input[0])};</div><div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;    }</div><div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;</div><div class="line"><a name="l00722"></a><span class="lineno"><a class="line" href="classpytorch_1_1_sigmoid.html#a272104b99e5c7dd6358b6ad66bac8334">  722</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_sigmoid.html#a272104b99e5c7dd6358b6ad66bac8334">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ac61be684e3426c6f8c53dc794ccf3a70">pytorch::sigmoid</a>(input[0])};</div><div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;    }</div><div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;  };</div><div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;</div><div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;  <span class="comment">/* Tanh - tested */</span></div><div class="line"><a name="l00728"></a><span class="lineno"><a class="line" href="classpytorch_1_1_tanh.html">  728</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_tanh.html">Tanh</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00730"></a><span class="lineno"><a class="line" href="classpytorch_1_1_tanh.html#abebdcdc2a41b9cca18a30309af154600">  730</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_tanh.html#abebdcdc2a41b9cca18a30309af154600">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#aaf715d23cef54abd1758cfaa439a0c0a">pytorch::tanh</a>(input[0])};</div><div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;    }</div><div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160;</div><div class="line"><a name="l00734"></a><span class="lineno"><a class="line" href="classpytorch_1_1_tanh.html#a0d593d22d6b94e751d8f119626fb3e1f">  734</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_tanh.html#a0d593d22d6b94e751d8f119626fb3e1f">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#aaf715d23cef54abd1758cfaa439a0c0a">pytorch::tanh</a>(input[0])};</div><div class="line"><a name="l00736"></a><span class="lineno">  736</span>&#160;    }</div><div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;  };</div><div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;</div><div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;  <span class="comment">/* Hardtanh - tested */</span></div><div class="line"><a name="l00740"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html">  740</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_hardtanh.html">Hardtanh</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">float</span> low, high;</div><div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00743"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html#a597d72b27db6b4647d91bdbef5b6a99c">  743</a></span>&#160;    <a class="code" href="classpytorch_1_1_hardtanh.html#a597d72b27db6b4647d91bdbef5b6a99c">Hardtanh</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> &amp;low = 1.f, <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;high = 1.f) : low(low), high(high) {}</div><div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;</div><div class="line"><a name="l00745"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html#a0dddd311bb37d3bfb37f1ea45a1337ee">  745</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_hardtanh.html#a0dddd311bb37d3bfb37f1ea45a1337ee">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a6b9e5bd40b9390dced2011dc1a2c6f27">pytorch::hardtanh</a>(input[0], low, high)};</div><div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;    }</div><div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;</div><div class="line"><a name="l00749"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html#a9ac35a8c4dd94eb271e032605c73a3fb">  749</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_hardtanh.html#a9ac35a8c4dd94eb271e032605c73a3fb">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00750"></a><span class="lineno">  750</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a6b9e5bd40b9390dced2011dc1a2c6f27">pytorch::hardtanh</a>(input[0], low, high)};</div><div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;    }</div><div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;  };</div><div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;</div><div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;  <span class="comment">/* ReLU - tested */</span></div><div class="line"><a name="l00755"></a><span class="lineno"><a class="line" href="classpytorch_1_1_re_l_u.html">  755</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_re_l_u.html">ReLU</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00756"></a><span class="lineno">  756</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00757"></a><span class="lineno"><a class="line" href="classpytorch_1_1_re_l_u.html#a5488d7103355ed0f8f92aaea5364f3e2">  757</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_re_l_u.html#a5488d7103355ed0f8f92aaea5364f3e2">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a8c699a8743e789f81ce5a9c0a119f557">pytorch::relu</a>(input[0])};</div><div class="line"><a name="l00759"></a><span class="lineno">  759</span>&#160;    }</div><div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;</div><div class="line"><a name="l00761"></a><span class="lineno"><a class="line" href="classpytorch_1_1_re_l_u.html#afc78ace7d3c4eba28a4344b5dcf24fe9">  761</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_re_l_u.html#afc78ace7d3c4eba28a4344b5dcf24fe9">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00762"></a><span class="lineno">  762</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a8c699a8743e789f81ce5a9c0a119f557">pytorch::relu</a>(input[0])};</div><div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;    }</div><div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;  };</div><div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;</div><div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;  <span class="comment">// Softmax is not a stable operation so it&#39;s making testing hard...</span></div><div class="line"><a name="l00767"></a><span class="lineno"><a class="line" href="classpytorch_1_1_softmax.html">  767</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_softmax.html">Softmax</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> { <span class="comment">// SO SLOW GOOD LORD</span></div><div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00769"></a><span class="lineno"><a class="line" href="classpytorch_1_1_softmax.html#a24909b8fdd420f9d0b6275dbcb3f8cc6">  769</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_softmax.html#a24909b8fdd420f9d0b6275dbcb3f8cc6">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00770"></a><span class="lineno">  770</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a97f9016d270bdb685bf51d1833001797">pytorch::softmax</a>(input[0])};</div><div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;    }</div><div class="line"><a name="l00772"></a><span class="lineno">  772</span>&#160;</div><div class="line"><a name="l00773"></a><span class="lineno"><a class="line" href="classpytorch_1_1_softmax.html#ad11cd227c282ff29eaafa26e491daaca">  773</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_softmax.html#ad11cd227c282ff29eaafa26e491daaca">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a97f9016d270bdb685bf51d1833001797">pytorch::softmax</a>(input[0])};</div><div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;    }</div><div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;  };</div><div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;</div><div class="line"><a name="l00778"></a><span class="lineno">  778</span>&#160;} <span class="comment">// pytorch</span></div><div class="line"><a name="l00779"></a><span class="lineno">  779</span>&#160;</div><div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;</div><div class="line"><a name="l00781"></a><span class="lineno">  781</span>&#160;</div><div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;<span class="preprocessor">#endif //PYTORCH_INFERENCE_LAYERS_HPP</span></div><div class="ttc" id="namespacepytorch_html_a97f9016d270bdb685bf51d1833001797"><div class="ttname"><a href="namespacepytorch.html#a97f9016d270bdb685bf51d1833001797">pytorch::softmax</a></div><div class="ttdeci">af::array softmax(const af::array &amp;a)</div><div class="ttdef"><b>Definition:</b> ops.hpp:292</div></div>
<div class="ttc" id="namespacepytorch_html_acb1b2c573dffc92bcb33e82ac1eb1ff8"><div class="ttname"><a href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">pytorch::from_numpy</a></div><div class="ttdeci">af::array from_numpy(PyArrayObject *array, int ndim, std::vector&lt; int &gt; dims)</div><div class="ttdoc">Converts a numpy array to an ArrayFire array. </div><div class="ttdef"><b>Definition:</b> utils.hpp:45</div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196a15d37568bf28ad3bce066ae5692e91de"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a15d37568bf28ad3bce066ae5692e91de">pytorch::w</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:43</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html_ad23e05cd109aaa2ddeaf132b0e5cc1f8"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html#ad23e05cd109aaa2ddeaf132b0e5cc1f8">pytorch::AvgPool2d::AvgPool2d</a></div><div class="ttdeci">AvgPool2d(const pooling_params_t &amp;params)</div><div class="ttdoc">Constructs the AvgPool2d layer. Requires pooling parameters that are functionally identical to the co...</div><div class="ttdef"><b>Definition:</b> layers.hpp:288</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_afeb76a74cb0f632466bc52dd12829ca5"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#afeb76a74cb0f632466bc52dd12829ca5">pytorch::Conv2d::add_bias</a></div><div class="ttdeci">void add_bias(const std::string &amp;bias_filename, const std::vector&lt; int &gt; &amp;bias_dims)</div><div class="ttdoc">Read in bias from a file given here if it wasn&amp;#39;t passed to the constructor. Overwrites current conten...</div><div class="ttdef"><b>Definition:</b> layers.hpp:195</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_a036ece17af42590a42f38e50633072de"><div class="ttname"><a href="classpytorch_1_1_slice4.html#a036ece17af42590a42f38e50633072de">pytorch::Slice4::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:664</div></div>
<div class="ttc" id="namespacepytorch_html_af79090de8fcb96630036887e5f7b8ea7"><div class="ttname"><a href="namespacepytorch.html#af79090de8fcb96630036887e5f7b8ea7">pytorch::cat2</a></div><div class="ttdeci">af::array cat2(const af::array &amp;input1, const af::array &amp;input2, const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> ops.hpp:193</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a2b0abcb252baef05e13f648df24af1cf"><div class="ttname"><a href="classpytorch_1_1_linear.html#a2b0abcb252baef05e13f648df24af1cf">pytorch::Linear::~Linear</a></div><div class="ttdeci">virtual ~Linear()</div><div class="ttdoc">Destructor - for now trivial, may need to take on some functionality. </div><div class="ttdef"><b>Definition:</b> layers.hpp:525</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_ac8bbc9c901cda2e77ac60abccf4de372"><div class="ttname"><a href="classpytorch_1_1_linear.html#ac8bbc9c901cda2e77ac60abccf4de372">pytorch::Linear::Linear</a></div><div class="ttdeci">Linear(const Linear &amp;other)</div><div class="ttdoc">Copy constructor, constructs another Linear object that is an exact copy of the argument. </div><div class="ttdef"><b>Definition:</b> layers.hpp:517</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_ab397c5ffb4526d2cd48c7ea64abc56b7"><div class="ttname"><a href="classpytorch_1_1_slice3.html#ab397c5ffb4526d2cd48c7ea64abc56b7">pytorch::Slice3::Slice3</a></div><div class="ttdeci">Slice3(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:634</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_a20f7615a9da65d34b247ec79a801c06e"><div class="ttname"><a href="classpytorch_1_1_branch.html#a20f7615a9da65d34b247ec79a801c06e">pytorch::Branch::Branch</a></div><div class="ttdeci">Branch(const int &amp;copies)</div><div class="ttdef"><b>Definition:</b> layers.hpp:595</div></div>
<div class="ttc" id="structpytorch_1_1conv__params__t_html"><div class="ttname"><a href="structpytorch_1_1conv__params__t.html">pytorch::conv_params_t</a></div><div class="ttdef"><b>Definition:</b> ops.hpp:39</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_aed74425320b96a734e7afcc1be2ac817"><div class="ttname"><a href="classpytorch_1_1_slice2.html#aed74425320b96a734e7afcc1be2ac817">pytorch::Slice2::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:620</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_ac596c3c020ec5ac7e324e6d32a7539bc"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#ac596c3c020ec5ac7e324e6d32a7539bc">pytorch::Conv2d::Conv2d</a></div><div class="ttdeci">Conv2d(const conv_params_t &amp;params, const std::string &amp;filters_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;filt_dims={}, const bool &amp;has_bias=false, const std::string &amp;bias_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;bias_dims={}, const std::string &amp;python_home=&quot;../scripts&quot;)</div><div class="ttdoc">Constructs a Conv2d object given the filenames and sizes of the requisite tensors. Also requires convolution parameters like the other constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:137</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html_ad8115f840f7937f47849357f8f05a336"><div class="ttname"><a href="classpytorch_1_1_concat4.html#ad8115f840f7937f47849357f8f05a336">pytorch::Concat4::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:706</div></div>
<div class="ttc" id="classpytorch_1_1_tanh_html"><div class="ttname"><a href="classpytorch_1_1_tanh.html">pytorch::Tanh</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:728</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html_ab7a24c04cf459171cd75876ee73032d0"><div class="ttname"><a href="classpytorch_1_1_concat2.html#ab7a24c04cf459171cd75876ee73032d0">pytorch::Concat2::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:680</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a44601eef2233bbf8cb6da963bcf1520e"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a44601eef2233bbf8cb6da963bcf1520e">pytorch::BatchNorm2d::add_running_mean</a></div><div class="ttdeci">void add_running_mean(const std::string &amp;running_mean_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;running_mean_dims={})</div><div class="ttdoc">Adds running_mean if it wasn&amp;#39;t added by the constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:419</div></div>
<div class="ttc" id="classpytorch_1_1_softmax_html_ad11cd227c282ff29eaafa26e491daaca"><div class="ttname"><a href="classpytorch_1_1_softmax.html#ad11cd227c282ff29eaafa26e491daaca">pytorch::Softmax::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:773</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_ab8a0e1cbc627b47c87a8cc5951b55e25"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#ab8a0e1cbc627b47c87a8cc5951b55e25">pytorch::BatchNorm2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Applies the forward pass of batch normalization. </div><div class="ttdef"><b>Definition:</b> layers.hpp:457</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html_a1904e62fdaee1476b737a364b5156be7"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html#a1904e62fdaee1476b737a364b5156be7">pytorch::AvgPool2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forwards pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:296</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html"><div class="ttname"><a href="classpytorch_1_1_branch.html">pytorch::Branch</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:591</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html">pytorch::MaxPool2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:236</div></div>
<div class="ttc" id="py__object_8hpp_html"><div class="ttname"><a href="py__object_8hpp.html">py_object.hpp</a></div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_af1a75e7f8473d605787c09320c51d63d"><div class="ttname"><a href="classpytorch_1_1_slice3.html#af1a75e7f8473d605787c09320c51d63d">pytorch::Slice3::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:640</div></div>
<div class="ttc" id="namespacepytorch_html_a94ec836f5c6229b0b05a2d5d0c083861"><div class="ttname"><a href="namespacepytorch.html#a94ec836f5c6229b0b05a2d5d0c083861">pytorch::conv2d</a></div><div class="ttdeci">af::array conv2d(const conv_params_t &amp;params, const af::array &amp;input, const af::array &amp;filters, const af::array &amp;bias, const bool &amp;has_bias)</div><div class="ttdoc">Performs convolution given exported pytorch filters. </div><div class="ttdef"><b>Definition:</b> ops.hpp:65</div></div>
<div class="ttc" id="classpytorch_1_1_skip_html"><div class="ttname"><a href="classpytorch_1_1_skip.html">pytorch::Skip</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:77</div></div>
<div class="ttc" id="classpytorch_1_1_tanh_html_abebdcdc2a41b9cca18a30309af154600"><div class="ttname"><a href="classpytorch_1_1_tanh.html#abebdcdc2a41b9cca18a30309af154600">pytorch::Tanh::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:730</div></div>
<div class="ttc" id="namespacepytorch_html_ae865095aad032ac1ea9516ae5361e0ab"><div class="ttname"><a href="namespacepytorch.html#ae865095aad032ac1ea9516ae5361e0ab">pytorch::batchnorm2d</a></div><div class="ttdeci">af::array batchnorm2d(const af::array &amp;gamma, const af::array &amp;beta, const af::array &amp;running_mean, const af::array &amp;running_variance, const float &amp;epsilon, const af::array &amp;input)</div><div class="ttdef"><b>Definition:</b> ops.hpp:214</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_acad1a59f2edc4a810ff46458f4da8c82"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#acad1a59f2edc4a810ff46458f4da8c82">pytorch::BatchNorm2d::BatchNorm2d</a></div><div class="ttdeci">BatchNorm2d(const af::array &amp;gamma, const af::array &amp;beta, const float &amp;running_mean, const float &amp;running_var, const float &amp;epsilon=1e-5)</div><div class="ttdoc">Constructs a BatchNorm2d object. </div><div class="ttdef"><b>Definition:</b> layers.hpp:337</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_a7405226a4261a588170c692ee7325cd8"><div class="ttname"><a href="classpytorch_1_1_slice3.html#a7405226a4261a588170c692ee7325cd8">pytorch::Slice3::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:644</div></div>
<div class="ttc" id="classpytorch_1_1_softmax_html_a24909b8fdd420f9d0b6275dbcb3f8cc6"><div class="ttname"><a href="classpytorch_1_1_softmax.html#a24909b8fdd420f9d0b6275dbcb3f8cc6">pytorch::Softmax::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:769</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html">pytorch::Hardtanh</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:740</div></div>
<div class="ttc" id="utils_8hpp_html"><div class="ttname"><a href="utils_8hpp.html">utils.hpp</a></div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196a1f250f3998835bb50ff8608dead82418"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a1f250f3998835bb50ff8608dead82418">pytorch::h</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:42</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a6849f3a4850596f32f05b51273ea4eb3"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a6849f3a4850596f32f05b51273ea4eb3">pytorch::MaxPool2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forward pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:265</div></div>
<div class="ttc" id="classpytorch_1_1_re_l_u_html_a5488d7103355ed0f8f92aaea5364f3e2"><div class="ttname"><a href="classpytorch_1_1_re_l_u.html#a5488d7103355ed0f8f92aaea5364f3e2">pytorch::ReLU::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:757</div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196a73a50f78ad527d77d9f062bf071de1b5"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a73a50f78ad527d77d9f062bf071de1b5">pytorch::k</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:41</div></div>
<div class="ttc" id="namespacepytorch_html_a78a38423eda0d20c5b3c61c69a0ce8c4"><div class="ttname"><a href="namespacepytorch.html#a78a38423eda0d20c5b3c61c69a0ce8c4">pytorch::avgpool</a></div><div class="ttdeci">af::array avgpool(const pooling_params_t &amp;params, const af::array &amp;input)</div><div class="ttdef"><b>Definition:</b> ops.hpp:255</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html"><div class="ttname"><a href="classpytorch_1_1_linear.html">pytorch::Linear</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:471</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html_af9ff578363eb1d53202e0614bc3c6aa1"><div class="ttname"><a href="classpytorch_1_1_concat4.html#af9ff578363eb1d53202e0614bc3c6aa1">pytorch::Concat4::Concat4</a></div><div class="ttdeci">Concat4(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:704</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html_a57470086b64b3b7ff5c50e2e3cd8cebf"><div class="ttname"><a href="classpytorch_1_1_concat3.html#a57470086b64b3b7ff5c50e2e3cd8cebf">pytorch::Concat3::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:695</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_a2704991f0818c418d24408d7360f9d68"><div class="ttname"><a href="classpytorch_1_1_slice2.html#a2704991f0818c418d24408d7360f9d68">pytorch::Slice2::Slice2</a></div><div class="ttdeci">Slice2(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:614</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a5f2ea435fea042c0677ecd665de1405b"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a5f2ea435fea042c0677ecd665de1405b">pytorch::MaxPool2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forward pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:255</div></div>
<div class="ttc" id="classpycpp_1_1py__object_html"><div class="ttname"><a href="classpycpp_1_1py__object.html">pycpp::py_object</a></div><div class="ttdef"><b>Definition:</b> py_object.hpp:488</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html_a3bea4ffd404197583dd5adecbc94e2f0"><div class="ttname"><a href="classpytorch_1_1_concat3.html#a3bea4ffd404197583dd5adecbc94e2f0">pytorch::Concat3::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:691</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a0b0318a61558f674bff2be8410da1fb5"><div class="ttname"><a href="classpytorch_1_1_linear.html#a0b0318a61558f674bff2be8410da1fb5">pytorch::Linear::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function, takes data and performs the Linear operation using the already-initialized weights ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:573</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_aaa119a9771aaea730dd58ac6e45e8167"><div class="ttname"><a href="classpytorch_1_1_slice2.html#aaa119a9771aaea730dd58ac6e45e8167">pytorch::Slice2::get_dim</a></div><div class="ttdeci">int get_dim() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:616</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html_a9ac35a8c4dd94eb271e032605c73a3fb"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html#a9ac35a8c4dd94eb271e032605c73a3fb">pytorch::Hardtanh::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:749</div></div>
<div class="ttc" id="classpytorch_1_1_skip_html_ab3833af82d8d8b7579b2515d6e06e5ce"><div class="ttname"><a href="classpytorch_1_1_skip.html#ab3833af82d8d8b7579b2515d6e06e5ce">pytorch::Skip::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">No-op forward. </div><div class="ttdef"><b>Definition:</b> layers.hpp:84</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_ad59f5c6c9fd3a6a238cfa50fa94e4019"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#ad59f5c6c9fd3a6a238cfa50fa94e4019">pytorch::Conv2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function, takes data and performs the Conv2d operation using the already-initialized filters ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:221</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a8c601902ed93f0afa8ab61e62110f19f"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a8c601902ed93f0afa8ab61e62110f19f">pytorch::MaxPool2d::MaxPool2d</a></div><div class="ttdeci">MaxPool2d(const pooling_params_t &amp;params)</div><div class="ttdoc">Constructs the MaxPool2d layer. Requires pooling parameters that are functionally equivalent to the c...</div><div class="ttdef"><b>Definition:</b> layers.hpp:247</div></div>
<div class="ttc" id="classpytorch_1_1_re_l_u_html_afc78ace7d3c4eba28a4344b5dcf24fe9"><div class="ttname"><a href="classpytorch_1_1_re_l_u.html#afc78ace7d3c4eba28a4344b5dcf24fe9">pytorch::ReLU::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:761</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_ae0d6f620eab11534bb3262580c571c8f"><div class="ttname"><a href="classpytorch_1_1_branch.html#ae0d6f620eab11534bb3262580c571c8f">pytorch::Branch::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:601</div></div>
<div class="ttc" id="classpytorch_1_1_layer_html_a7a766ac20be5e818e497e6f2f05a2c8d"><div class="ttname"><a href="classpytorch_1_1_layer.html#a7a766ac20be5e818e497e6f2f05a2c8d">pytorch::Layer::operator()</a></div><div class="ttdeci">virtual std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)=0</div><div class="ttdoc">Forward function for this layer. </div></div>
<div class="ttc" id="classpytorch_1_1_layer_html_a1abb45857b18f70a9a95ae16a69f968d"><div class="ttname"><a href="classpytorch_1_1_layer.html#a1abb45857b18f70a9a95ae16a69f968d">pytorch::Layer::forward</a></div><div class="ttdeci">virtual std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)=0</div><div class="ttdoc">Forward function for this layer. </div></div>
<div class="ttc" id="namespacepytorch_html_ac48fbbcee5e49075953d6b3117eaa329"><div class="ttname"><a href="namespacepytorch.html#ac48fbbcee5e49075953d6b3117eaa329">pytorch::cat4</a></div><div class="ttdeci">af::array cat4(const af::array &amp;input1, const af::array &amp;input2, const af::array &amp;input3, const af::array &amp;input4, const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> ops.hpp:206</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a6d86c19268604c3c35a7958bb55d0329"><div class="ttname"><a href="classpytorch_1_1_linear.html#a6d86c19268604c3c35a7958bb55d0329">pytorch::Linear::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function, takes data and performs the Linear operation using the already-initialized weights ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:584</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_a56760a37afd47d7efe851abd51b33568"><div class="ttname"><a href="classpytorch_1_1_branch.html#a56760a37afd47d7efe851abd51b33568">pytorch::Branch::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:605</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html"><div class="ttname"><a href="classpytorch_1_1_slice4.html">pytorch::Slice4</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:650</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a850c81192d2f73e96f42700b94091a57"><div class="ttname"><a href="classpytorch_1_1_linear.html#a850c81192d2f73e96f42700b94091a57">pytorch::Linear::set_has_bias</a></div><div class="ttdeci">void set_has_bias(bool has_bias)</div><div class="ttdoc">Sets whether or not this layer has bias. If no, then this should be called. Otherwise, it&amp;#39;s unnecessary. </div><div class="ttdef"><b>Definition:</b> layers.hpp:562</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a708c9fbeed102fe07577f4d9321b2261"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a708c9fbeed102fe07577f4d9321b2261">pytorch::BatchNorm2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Applies the forward pass of batch normalization. </div><div class="ttdef"><b>Definition:</b> layers.hpp:447</div></div>
<div class="ttc" id="namespacepytorch_html_a6b9e5bd40b9390dced2011dc1a2c6f27"><div class="ttname"><a href="namespacepytorch.html#a6b9e5bd40b9390dced2011dc1a2c6f27">pytorch::hardtanh</a></div><div class="ttdeci">af::array hardtanh(const af::array &amp;a, const float &amp;low=1.f, const float &amp;high=1.f)</div><div class="ttdef"><b>Definition:</b> ops.hpp:276</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html_aad8088bbad685a8d07ea11b2fa72d2ff"><div class="ttname"><a href="classpytorch_1_1_concat4.html#aad8088bbad685a8d07ea11b2fa72d2ff">pytorch::Concat4::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:710</div></div>
<div class="ttc" id="namespacepycpp_html_a7589e2bbb5161df0a000a2e0026e6e95"><div class="ttname"><a href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a></div><div class="ttdeci">PyObject * to_python(const std::vector&lt; int &gt; &amp;vec)</div><div class="ttdoc">Takes a vector to a python list. </div><div class="ttdef"><b>Definition:</b> py_object.hpp:81</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a54664c298098621bc625e899c96f7af6"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a54664c298098621bc625e899c96f7af6">pytorch::BatchNorm2d::add_beta</a></div><div class="ttdeci">void add_beta(const std::string &amp;beta_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;beta_dims={})</div><div class="ttdoc">Adds beta if it wasn&amp;#39;t added by the constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:405</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html"><div class="ttname"><a href="classpytorch_1_1_concat2.html">pytorch::Concat2</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:671</div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196a72642ee422e2c907c36ca4762478cb3d"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a72642ee422e2c907c36ca4762478cb3d">pytorch::n</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:40</div></div>
<div class="ttc" id="namespacepytorch_html_a8c699a8743e789f81ce5a9c0a119f557"><div class="ttname"><a href="namespacepytorch.html#a8c699a8743e789f81ce5a9c0a119f557">pytorch::relu</a></div><div class="ttdeci">af::array relu(const af::array &amp;a)</div><div class="ttdef"><b>Definition:</b> ops.hpp:284</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_ac7173111158536b89905c320e53cc4b8"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#ac7173111158536b89905c320e53cc4b8">pytorch::Conv2d::add_filters</a></div><div class="ttdeci">void add_filters(const ::std::string &amp;filters_filename, const std::vector&lt; int &gt; &amp;filt_dims)</div><div class="ttdoc">Read in filters from a file given here if it wasn&amp;#39;t passed to the constructor. Overwrites current con...</div><div class="ttdef"><b>Definition:</b> layers.hpp:180</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html_a6f45f28982b7a61093026c6715dfa9b5"><div class="ttname"><a href="classpytorch_1_1_concat2.html#a6f45f28982b7a61093026c6715dfa9b5">pytorch::Concat2::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:676</div></div>
<div class="ttc" id="namespacepytorch_html_ad49eda1612a5d32ca493c4980741542e"><div class="ttname"><a href="namespacepytorch.html#ad49eda1612a5d32ca493c4980741542e">pytorch::linear</a></div><div class="ttdeci">af::array linear(const af::array &amp;input, const af::array &amp;weight, const af::array &amp;bias, const bool &amp;has_bias)</div><div class="ttdoc">Performs the linear transformation y = Wx + b. </div><div class="ttdef"><b>Definition:</b> ops.hpp:126</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_abcf999345ff5e740f379e3bb9fe93e9e"><div class="ttname"><a href="classpytorch_1_1_slice2.html#abcf999345ff5e740f379e3bb9fe93e9e">pytorch::Slice2::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:624</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html"><div class="ttname"><a href="classpytorch_1_1_conv2d.html">pytorch::Conv2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:106</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html_afca3a26b9eb7824646e34ea0071331ad"><div class="ttname"><a href="classpytorch_1_1_concat3.html#afca3a26b9eb7824646e34ea0071331ad">pytorch::Concat3::Concat3</a></div><div class="ttdeci">Concat3(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:689</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_a227cb3c33ab5c5752bbe365943660bf8"><div class="ttname"><a href="classpytorch_1_1_slice4.html#a227cb3c33ab5c5752bbe365943660bf8">pytorch::Slice4::get_dim</a></div><div class="ttdeci">int get_dim() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:656</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html">pytorch::BatchNorm2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:319</div></div>
<div class="ttc" id="namespacepytorch_html_ac61be684e3426c6f8c53dc794ccf3a70"><div class="ttname"><a href="namespacepytorch.html#ac61be684e3426c6f8c53dc794ccf3a70">pytorch::sigmoid</a></div><div class="ttdeci">af::array sigmoid(const af::array &amp;a)</div><div class="ttdef"><b>Definition:</b> ops.hpp:272</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_a7c4b6e3a751b69ed1aaf13801aa989c0"><div class="ttname"><a href="classpytorch_1_1_slice4.html#a7c4b6e3a751b69ed1aaf13801aa989c0">pytorch::Slice4::Slice4</a></div><div class="ttdeci">Slice4(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:654</div></div>
<div class="ttc" id="classpytorch_1_1_re_l_u_html"><div class="ttname"><a href="classpytorch_1_1_re_l_u.html">pytorch::ReLU</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:755</div></div>
<div class="ttc" id="namespacepytorch_html_aaf715d23cef54abd1758cfaa439a0c0a"><div class="ttname"><a href="namespacepytorch.html#aaf715d23cef54abd1758cfaa439a0c0a">pytorch::tanh</a></div><div class="ttdeci">af::array tanh(const af::array &amp;a)</div><div class="ttdef"><b>Definition:</b> ops.hpp:280</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_a882cce34197fcb801aae899b3d7b6a91"><div class="ttname"><a href="classpytorch_1_1_slice4.html#a882cce34197fcb801aae899b3d7b6a91">pytorch::Slice4::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:660</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a625e155c4c0e9aafa899ddcba2ce5fc6"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a625e155c4c0e9aafa899ddcba2ce5fc6">pytorch::Conv2d::Conv2d</a></div><div class="ttdeci">Conv2d(const Conv2d &amp;other)</div><div class="ttdoc">Copy constructor, constructs a Conv2d object that is exactly a copy of the argument. </div><div class="ttdef"><b>Definition:</b> layers.hpp:162</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html">pytorch::AvgPool2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:278</div></div>
<div class="ttc" id="namespacepytorch_html"><div class="ttname"><a href="namespacepytorch.html">pytorch</a></div><div class="ttdef"><b>Definition:</b> inference_engine.hpp:37</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html"><div class="ttname"><a href="classpytorch_1_1_concat4.html">pytorch::Concat4</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:701</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a953a1db977476c1b7d963459a63b9034"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a953a1db977476c1b7d963459a63b9034">pytorch::Conv2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function, takes data and performs the Conv2d operation using the already-initialized filters ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:210</div></div>
<div class="ttc" id="classpytorch_1_1_sigmoid_html_a272104b99e5c7dd6358b6ad66bac8334"><div class="ttname"><a href="classpytorch_1_1_sigmoid.html#a272104b99e5c7dd6358b6ad66bac8334">pytorch::Sigmoid::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:722</div></div>
<div class="ttc" id="classpytorch_1_1_skip_html_a968c864ee798307240bd9ea3d17156c3"><div class="ttname"><a href="classpytorch_1_1_skip.html#a968c864ee798307240bd9ea3d17156c3">pytorch::Skip::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">No-op forward. </div><div class="ttdef"><b>Definition:</b> layers.hpp:93</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a8cbffb226f756dfabc3fcbb80c075cef"><div class="ttname"><a href="classpytorch_1_1_linear.html#a8cbffb226f756dfabc3fcbb80c075cef">pytorch::Linear::add_weights</a></div><div class="ttdeci">void add_weights(const std::string &amp;weights_filename, const std::vector&lt; int &gt; &amp;weights_dims)</div><div class="ttdoc">Read in weights from a file given here if it wasn&amp;#39;t passed to the constructor. Overwrites current con...</div><div class="ttdef"><b>Definition:</b> layers.hpp:534</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_ad061ae2fec18baa95cc7b9b854b57f92"><div class="ttname"><a href="classpytorch_1_1_linear.html#ad061ae2fec18baa95cc7b9b854b57f92">pytorch::Linear::Linear</a></div><div class="ttdeci">Linear(const std::string &amp;weights_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;weights_dims={}, const bool has_bias=false, const std::string &amp;bias_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;bias_dims={}, const std::string &amp;python_home=&quot;../scripts&quot;)</div><div class="ttdoc">Constructs a Linear object given the filenames and sizes of the requisite tensors. </div><div class="ttdef"><b>Definition:</b> layers.hpp:497</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html_a597d72b27db6b4647d91bdbef5b6a99c"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html#a597d72b27db6b4647d91bdbef5b6a99c">pytorch::Hardtanh::Hardtanh</a></div><div class="ttdeci">Hardtanh(const float &amp;low=1.f, const float &amp;high=1.f)</div><div class="ttdef"><b>Definition:</b> layers.hpp:743</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html"><div class="ttname"><a href="classpytorch_1_1_slice3.html">pytorch::Slice3</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:630</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a5e7eb9604dbc94ca62edd04ec8944faf"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a5e7eb9604dbc94ca62edd04ec8944faf">pytorch::Conv2d::~Conv2d</a></div><div class="ttdeci">virtual ~Conv2d()</div><div class="ttdoc">Destructor - for now trivial, may need to take on some functionality. </div><div class="ttdef"><b>Definition:</b> layers.hpp:171</div></div>
<div class="ttc" id="classpytorch_1_1_tanh_html_a0d593d22d6b94e751d8f119626fb3e1f"><div class="ttname"><a href="classpytorch_1_1_tanh.html#a0d593d22d6b94e751d8f119626fb3e1f">pytorch::Tanh::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:734</div></div>
<div class="ttc" id="namespacepytorch_html_a72df22b8266ef90d0b94983f84ad52cb"><div class="ttname"><a href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a></div><div class="ttdeci">std::vector&lt; af::array &gt; split_branch(const af::array &amp;input, const int &amp;slices, const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> ops.hpp:159</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html_a4295d2772036dd4c52c68cf4cc533f9c"><div class="ttname"><a href="classpytorch_1_1_concat2.html#a4295d2772036dd4c52c68cf4cc533f9c">pytorch::Concat2::Concat2</a></div><div class="ttdeci">Concat2(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:674</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html_a0dddd311bb37d3bfb37f1ea45a1337ee"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html#a0dddd311bb37d3bfb37f1ea45a1337ee">pytorch::Hardtanh::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:745</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_af70ee99c631a3c21d87ba0460130a437"><div class="ttname"><a href="classpytorch_1_1_branch.html#af70ee99c631a3c21d87ba0460130a437">pytorch::Branch::get_copies</a></div><div class="ttdeci">int get_copies() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:597</div></div>
<div class="ttc" id="classpytorch_1_1_sigmoid_html"><div class="ttname"><a href="classpytorch_1_1_sigmoid.html">pytorch::Sigmoid</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:716</div></div>
<div class="ttc" id="classpytorch_1_1_layer_html"><div class="ttname"><a href="classpytorch_1_1_layer.html">pytorch::Layer</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:55</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html_a6a08e267be98ce762c062052cb9d046b"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html#a6a08e267be98ce762c062052cb9d046b">pytorch::AvgPool2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forwards pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:306</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html"><div class="ttname"><a href="classpytorch_1_1_slice2.html">pytorch::Slice2</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:610</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a2d4e756090fe5a4c9637ad97959d7614"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a2d4e756090fe5a4c9637ad97959d7614">pytorch::Conv2d::Conv2d</a></div><div class="ttdeci">Conv2d(const conv_params_t &amp;params, const af::array &amp;filters, const af::array &amp;bias)</div><div class="ttdoc">Constructs a Conv2d object given parameters, filters, and bias tensors. </div><div class="ttdef"><b>Definition:</b> layers.hpp:122</div></div>
<div class="ttc" id="classpytorch_1_1_softmax_html"><div class="ttname"><a href="classpytorch_1_1_softmax.html">pytorch::Softmax</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:767</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_a53fbbf80acc37d0d12520f583158461e"><div class="ttname"><a href="classpytorch_1_1_slice3.html#a53fbbf80acc37d0d12520f583158461e">pytorch::Slice3::get_dim</a></div><div class="ttdeci">int get_dim() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:636</div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196">pytorch::dims</a></div><div class="ttdeci">dims</div><div class="ttdoc">Convenience enum to use whenever you need to specify a dimension (like in Concat) ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:39</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a1816381a3443fc87ee9b25efd0cfe6e3"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a1816381a3443fc87ee9b25efd0cfe6e3">pytorch::BatchNorm2d::add_running_var</a></div><div class="ttdeci">void add_running_var(const std::string &amp;running_var_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;running_var_dims={})</div><div class="ttdoc">Adds running_var if it wasn&amp;#39;t added by the constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:433</div></div>
<div class="ttc" id="classpytorch_1_1_sigmoid_html_a8e7e598171e919a5dd3dfd54ad38dbdc"><div class="ttname"><a href="classpytorch_1_1_sigmoid.html#a8e7e598171e919a5dd3dfd54ad38dbdc">pytorch::Sigmoid::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:718</div></div>
<div class="ttc" id="namespacepytorch_html_aa1b0dc2ffe07685855199e859712f0a3"><div class="ttname"><a href="namespacepytorch.html#aa1b0dc2ffe07685855199e859712f0a3">pytorch::copy_branch</a></div><div class="ttdeci">std::vector&lt; af::array &gt; copy_branch(const af::array &amp;input, const int &amp;copies)</div><div class="ttdef"><b>Definition:</b> ops.hpp:150</div></div>
<div class="ttc" id="namespacepytorch_html_aacf5782da70434cc8657a5ff4c612fc5"><div class="ttname"><a href="namespacepytorch.html#aacf5782da70434cc8657a5ff4c612fc5">pytorch::maxpool</a></div><div class="ttdeci">af::array maxpool(const pooling_params_t &amp;params, const af::array &amp;input, af::array &amp;indices)</div><div class="ttdef"><b>Definition:</b> ops.hpp:232</div></div>
<div class="ttc" id="ops_8hpp_html"><div class="ttname"><a href="ops_8hpp.html">ops.hpp</a></div><div class="ttdoc">Holds the parameters needed for convolution as well as a convenience function to send them to a std::...</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a4db382b11a3f91778797a6e940692d86"><div class="ttname"><a href="classpytorch_1_1_linear.html#a4db382b11a3f91778797a6e940692d86">pytorch::Linear::add_bias</a></div><div class="ttdeci">void add_bias(const std::string &amp;bias_filename, const std::vector&lt; int &gt; &amp;bias_dims)</div><div class="ttdoc">Read in bias from a file given here if it wasn&amp;#39;t passed to the constructor. Overwrites current conten...</div><div class="ttdef"><b>Definition:</b> layers.hpp:549</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_af29892810fccc85d2bc202c16c5d49fe"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#af29892810fccc85d2bc202c16c5d49fe">pytorch::BatchNorm2d::add_gamma</a></div><div class="ttdeci">void add_gamma(const std::string &amp;gamma_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;gamma_dims={})</div><div class="ttdoc">Adds gamma to the layer if the name wasn&amp;#39;t passed to the constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:391</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html"><div class="ttname"><a href="classpytorch_1_1_concat3.html">pytorch::Concat3</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:686</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a910802963973f5d64fb6d281635a1035"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a910802963973f5d64fb6d281635a1035">pytorch::BatchNorm2d::BatchNorm2d</a></div><div class="ttdeci">BatchNorm2d(const std::string &amp;gamma_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;gamma_dims={}, const std::string &amp;beta_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;beta_dims={}, const std::string &amp;running_mean_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;running_mean_dims={}, const std::string &amp;running_var_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;running_var_dims={}, const float &amp;epsilon=1e-5, const std::string &amp;python_home=&quot;../scripts&quot;)</div><div class="ttdoc">Constructs a BatchNorm2d object and loads the requisite tensors in from filenames and sizes...</div><div class="ttdef"><b>Definition:</b> layers.hpp:359</div></div>
<div class="ttc" id="namespacepytorch_html_a9243e92d218fdf3718ab963e4005988e"><div class="ttname"><a href="namespacepytorch.html#a9243e92d218fdf3718ab963e4005988e">pytorch::cat3</a></div><div class="ttdeci">af::array cat3(const af::array &amp;input1, const af::array &amp;input2, const af::array &amp;input3, const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> ops.hpp:199</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a47740884c0ce199daecd9958bd6b6ca3"><div class="ttname"><a href="classpytorch_1_1_linear.html#a47740884c0ce199daecd9958bd6b6ca3">pytorch::Linear::Linear</a></div><div class="ttdeci">Linear(const af::array &amp;weights, const af::array &amp;bias)</div><div class="ttdoc">Constructs a Linear object given weights, and bias tensors. </div><div class="ttdef"><b>Definition:</b> layers.hpp:485</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="layers_8hpp.html">layers.hpp</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
