<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>pytorch-inference: layers.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">pytorch-inference
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('layers_8hpp_source.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">layers.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="layers_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Created by Aman LaChapelle on 5/19/17.</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">// pytorch_inference</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">// Copyright (c) 2017 Aman LaChapelle</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">// Full license at pytorch_inference/LICENSE.txt</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">    This program is free software: you can redistribute it and/or modify</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment">    it under the terms of the GNU General Public License as published by</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">    the Free Software Foundation, either version 3 of the License, or</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment">    (at your option) any later version.</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">    This program is distributed in the hope that it will be useful,</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">    but WITHOUT ANY WARRANTY; without even the implied warranty of</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment">    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment">    GNU General Public License for more details.</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment">    You should have received a copy of the GNU General Public License</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment">    along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#ifndef PYTORCH_INFERENCE_LAYERS_HPP</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="preprocessor">#define PYTORCH_INFERENCE_LAYERS_HPP</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &lt;arrayfire.h&gt;</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="ops_8hpp.html">ops.hpp</a>&quot;</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="utils_8hpp.html">utils.hpp</a>&quot;</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="py__object_8hpp.html">py_object.hpp</a>&quot;</span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacepytorch.html">pytorch</a> {</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;</div><div class="line"><a name="l00044"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196">   44</a></span>&#160;  <span class="keyword">enum</span> <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196">dims</a> {</div><div class="line"><a name="l00045"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a72642ee422e2c907c36ca4762478cb3d">   45</a></span>&#160;    <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a72642ee422e2c907c36ca4762478cb3d">n</a> = 3,</div><div class="line"><a name="l00046"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a73a50f78ad527d77d9f062bf071de1b5">   46</a></span>&#160;    <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a73a50f78ad527d77d9f062bf071de1b5">k</a> = 2,</div><div class="line"><a name="l00047"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a1f250f3998835bb50ff8608dead82418">   47</a></span>&#160;    <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a1f250f3998835bb50ff8608dead82418">h</a> = 0,</div><div class="line"><a name="l00048"></a><span class="lineno"><a class="line" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a15d37568bf28ad3bce066ae5692e91de">   48</a></span>&#160;    <a class="code" href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a15d37568bf28ad3bce066ae5692e91de">w</a> = 1</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;  };</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;</div><div class="line"><a name="l00060"></a><span class="lineno"><a class="line" href="classpytorch_1_1_layer.html">   60</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    <span class="keyword">inline</span> <span class="keyword">virtual</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_layer.html#a1abb45857b18f70a9a95ae16a69f968d">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input) = 0;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;    <span class="keyword">inline</span> <span class="keyword">virtual</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_layer.html#a7a766ac20be5e818e497e6f2f05a2c8d">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input) = 0;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;  };</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;</div><div class="line"><a name="l00082"></a><span class="lineno"><a class="line" href="classpytorch_1_1_skip.html">   82</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_skip.html">Skip</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00089"></a><span class="lineno"><a class="line" href="classpytorch_1_1_skip.html#ab3833af82d8d8b7579b2515d6e06e5ce">   89</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_skip.html#ab3833af82d8d8b7579b2515d6e06e5ce">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;      <span class="keywordflow">return</span> input;</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    }</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;</div><div class="line"><a name="l00098"></a><span class="lineno"><a class="line" href="classpytorch_1_1_skip.html#a968c864ee798307240bd9ea3d17156c3">   98</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_skip.html#a968c864ee798307240bd9ea3d17156c3">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;      <span class="keywordflow">return</span> input;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    }</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;  };</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;</div><div class="line"><a name="l00111"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html">  111</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_conv2d.html">Conv2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00113"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a54285d3747c0e5db24dbbd86245fd4eb">  113</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_conv2d.html#a54285d3747c0e5db24dbbd86245fd4eb">filters</a>;</div><div class="line"><a name="l00114"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a69aa20f2f1e771bbb4048a682c44a4a7">  114</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_conv2d.html#a69aa20f2f1e771bbb4048a682c44a4a7">bias</a>;</div><div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a124b1cab460114aa17dfe76ed1b46fce">  115</a></span>&#160;    <a class="code" href="structpytorch_1_1conv__params__t.html">conv_params_t</a> <a class="code" href="classpytorch_1_1_conv2d.html#a124b1cab460114aa17dfe76ed1b46fce">params</a>;</div><div class="line"><a name="l00116"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#af2ca65a5d5e3272b0f8963163d846924">  116</a></span>&#160;    <a class="code" href="classpycpp_1_1py__object.html">pycpp::py_object</a> <a class="code" href="classpytorch_1_1_conv2d.html#af2ca65a5d5e3272b0f8963163d846924">utils</a>;</div><div class="line"><a name="l00117"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#ac6e2cd68c9a2056e9cb5b5ed643ca057">  117</a></span>&#160;    <span class="keywordtype">bool</span> <a class="code" href="classpytorch_1_1_conv2d.html#ac6e2cd68c9a2056e9cb5b5ed643ca057">has_bias</a>;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00127"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a2d4e756090fe5a4c9637ad97959d7614">  127</a></span>&#160;    <a class="code" href="classpytorch_1_1_conv2d.html#a2d4e756090fe5a4c9637ad97959d7614">Conv2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">conv_params_t</a> &amp;params,</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;           <span class="keyword">const</span> af::array &amp;filters,</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;           <span class="keyword">const</span> af::array &amp;bias) : params(params), filters(filters), bias(bias) { }</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;</div><div class="line"><a name="l00142"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#ac596c3c020ec5ac7e324e6d32a7539bc">  142</a></span>&#160;    <a class="code" href="classpytorch_1_1_conv2d.html#ac596c3c020ec5ac7e324e6d32a7539bc">Conv2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">conv_params_t</a> &amp;params,</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;           <span class="keyword">const</span> std::string &amp;filters_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;           <span class="keyword">const</span> std::vector&lt;int&gt; &amp;filt_dims = {},</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;           <span class="keyword">const</span> <span class="keywordtype">bool</span> &amp;has_bias = <span class="keyword">false</span>,</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;           <span class="keyword">const</span> std::string &amp;bias_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;           <span class="keyword">const</span> std::vector&lt;int&gt; &amp;bias_dims = {},</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;           <span class="keyword">const</span> std::string &amp;python_home = <span class="stringliteral">&quot;../scripts&quot;</span>) : params(params),</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;                                                            utils(<span class="stringliteral">&quot;utils&quot;</span>, python_home),</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;                                                            has_bias(has_bias) {</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;      <span class="keywordflow">if</span> (!filters_filename.empty()){</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;        this-&gt;add_filters(filters_filename, filt_dims);</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;      }</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;      <span class="keywordflow">if</span> (!bias_filename.empty() &amp;&amp; has_bias){</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        this-&gt;add_bias(bias_filename, bias_dims);</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;      }</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    }</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;</div><div class="line"><a name="l00167"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a625e155c4c0e9aafa899ddcba2ce5fc6">  167</a></span>&#160;    <a class="code" href="classpytorch_1_1_conv2d.html#a625e155c4c0e9aafa899ddcba2ce5fc6">Conv2d</a>(<span class="keyword">const</span> <a class="code" href="classpytorch_1_1_conv2d.html">Conv2d</a> &amp;other){</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;      filters = other.<a class="code" href="classpytorch_1_1_conv2d.html#a54285d3747c0e5db24dbbd86245fd4eb">filters</a>;</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;      bias = other.<a class="code" href="classpytorch_1_1_conv2d.html#a69aa20f2f1e771bbb4048a682c44a4a7">bias</a>;</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;      params = other.<a class="code" href="classpytorch_1_1_conv2d.html#a124b1cab460114aa17dfe76ed1b46fce">params</a>;</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;    }</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;</div><div class="line"><a name="l00176"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a5e7eb9604dbc94ca62edd04ec8944faf">  176</a></span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classpytorch_1_1_conv2d.html#a5e7eb9604dbc94ca62edd04ec8944faf">~Conv2d</a>() {}</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;</div><div class="line"><a name="l00185"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#ac7173111158536b89905c320e53cc4b8">  185</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_conv2d.html#ac7173111158536b89905c320e53cc4b8">add_filters</a>(const::std::string &amp;filters_filename,</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;                            <span class="keyword">const</span> std::vector&lt;int&gt; &amp;filt_dims){</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;      assert(filt_dims.size() &gt; 0);</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;      PyObject *filts = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(filters_filename)});</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;      assert(filts);</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;      filters = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(filts), filt_dims.size(), filt_dims);</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    }</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;</div><div class="line"><a name="l00200"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#afeb76a74cb0f632466bc52dd12829ca5">  200</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_conv2d.html#afeb76a74cb0f632466bc52dd12829ca5">add_bias</a>(<span class="keyword">const</span> std::string &amp;bias_filename,</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;                         <span class="keyword">const</span> std::vector&lt;int&gt; &amp;bias_dims){</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;      assert(bias_dims.size() &gt; 0);</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;      PyObject *bs = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(bias_filename)});</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;      assert(bs);</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;      bias = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(bs), bias_dims.size(), bias_dims);</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;    }</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;</div><div class="line"><a name="l00215"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#a953a1db977476c1b7d963459a63b9034">  215</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_conv2d.html#a953a1db977476c1b7d963459a63b9034">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a94ec836f5c6229b0b05a2d5d0c083861">conv2d</a>(params, input[0], filters, bias, has_bias)};</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;    }</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;</div><div class="line"><a name="l00226"></a><span class="lineno"><a class="line" href="classpytorch_1_1_conv2d.html#ad59f5c6c9fd3a6a238cfa50fa94e4019">  226</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_conv2d.html#ad59f5c6c9fd3a6a238cfa50fa94e4019">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a94ec836f5c6229b0b05a2d5d0c083861">conv2d</a>(params, input[0], filters, bias, has_bias)};</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;    }</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;  };</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;</div><div class="line"><a name="l00241"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html">  241</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_max_pool2d.html">MaxPool2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00243"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a01ce0020e17604df233fccdd235d265f">  243</a></span>&#160;    <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> <a class="code" href="classpytorch_1_1_max_pool2d.html#a01ce0020e17604df233fccdd235d265f">params</a>;</div><div class="line"><a name="l00244"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a3251f7f29fd9ef9c1d096301f3d120c3">  244</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_max_pool2d.html#a3251f7f29fd9ef9c1d096301f3d120c3">indices</a>;</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00252"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a8c601902ed93f0afa8ab61e62110f19f">  252</a></span>&#160;    <a class="code" href="classpytorch_1_1_max_pool2d.html#a8c601902ed93f0afa8ab61e62110f19f">MaxPool2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> &amp;params) : params(params) {}</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;</div><div class="line"><a name="l00254"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a5f16e26478688ec83fa6ebc52b463973">  254</a></span>&#160;    <span class="keyword">inline</span> af::array <a class="code" href="classpytorch_1_1_max_pool2d.html#a5f16e26478688ec83fa6ebc52b463973">get_indices</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;      <span class="keywordflow">return</span> indices;</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;    }</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;</div><div class="line"><a name="l00264"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a5f2ea435fea042c0677ecd665de1405b">  264</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_max_pool2d.html#a5f2ea435fea042c0677ecd665de1405b">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#aacf5782da70434cc8657a5ff4c612fc5">pytorch::maxpool</a>(params, input[0], indices)};</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;    }</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;</div><div class="line"><a name="l00274"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_pool2d.html#a6849f3a4850596f32f05b51273ea4eb3">  274</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_max_pool2d.html#a6849f3a4850596f32f05b51273ea4eb3">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#aacf5782da70434cc8657a5ff4c612fc5">pytorch::maxpool</a>(params, input[0], indices)};</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;    }</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;  };</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;</div><div class="line"><a name="l00287"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_unpool2d.html">  287</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_max_unpool2d.html">MaxUnpool2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00289"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_unpool2d.html#a9b1e85a9ead15064ae02813a7432ee76">  289</a></span>&#160;    <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> <a class="code" href="classpytorch_1_1_max_unpool2d.html#a9b1e85a9ead15064ae02813a7432ee76">params</a>;</div><div class="line"><a name="l00290"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_unpool2d.html#a6b52ffb75b96367f46135a524fdd8a53">  290</a></span>&#160;    <span class="keyword">const</span> <a class="code" href="classpytorch_1_1_max_pool2d.html">MaxPool2d</a> *<a class="code" href="classpytorch_1_1_max_unpool2d.html#a6b52ffb75b96367f46135a524fdd8a53">mp_ref</a>;</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00298"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_unpool2d.html#af0b4cba5f7c22bc03b0d32f39ff6423f">  298</a></span>&#160;    <a class="code" href="classpytorch_1_1_max_unpool2d.html#af0b4cba5f7c22bc03b0d32f39ff6423f">MaxUnpool2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> &amp;params, <span class="keyword">const</span> <a class="code" href="classpytorch_1_1_max_pool2d.html">MaxPool2d</a> *mp_ref) : params(params), mp_ref(mp_ref) {}</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;</div><div class="line"><a name="l00306"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_unpool2d.html#a825b92beb3f4120595eb7d1288201802">  306</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_max_unpool2d.html#a825b92beb3f4120595eb7d1288201802">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a12e2103bef62222f09265c609d047299">pytorch::unpool</a>(params, input[0], mp_ref-&gt;<a class="code" href="classpytorch_1_1_max_pool2d.html#a5f16e26478688ec83fa6ebc52b463973">get_indices</a>())};</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    }</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;</div><div class="line"><a name="l00316"></a><span class="lineno"><a class="line" href="classpytorch_1_1_max_unpool2d.html#a81abe04136f9c82a92e553ea354968ed">  316</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_max_unpool2d.html#a81abe04136f9c82a92e553ea354968ed">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a12e2103bef62222f09265c609d047299">pytorch::unpool</a>(params, input[0], mp_ref-&gt;<a class="code" href="classpytorch_1_1_max_pool2d.html#a5f16e26478688ec83fa6ebc52b463973">get_indices</a>())};</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;    }</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;  };</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;</div><div class="line"><a name="l00329"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html">  329</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_avg_pool2d.html">AvgPool2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00331"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html#a1256dba0f7f4207327a70573687aa66b">  331</a></span>&#160;    <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> <a class="code" href="classpytorch_1_1_avg_pool2d.html#a1256dba0f7f4207327a70573687aa66b">params</a>;</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00339"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html#ad23e05cd109aaa2ddeaf132b0e5cc1f8">  339</a></span>&#160;    <a class="code" href="classpytorch_1_1_avg_pool2d.html#ad23e05cd109aaa2ddeaf132b0e5cc1f8">AvgPool2d</a>(<span class="keyword">const</span> <a class="code" href="structpytorch_1_1conv__params__t.html">pooling_params_t</a> &amp;params) : params(params) {}</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;</div><div class="line"><a name="l00347"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html#a1904e62fdaee1476b737a364b5156be7">  347</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_avg_pool2d.html#a1904e62fdaee1476b737a364b5156be7">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a78a38423eda0d20c5b3c61c69a0ce8c4">pytorch::avgpool</a>(params, input[0])};</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;    }</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;</div><div class="line"><a name="l00357"></a><span class="lineno"><a class="line" href="classpytorch_1_1_avg_pool2d.html#a6a08e267be98ce762c062052cb9d046b">  357</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_avg_pool2d.html#a6a08e267be98ce762c062052cb9d046b">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a78a38423eda0d20c5b3c61c69a0ce8c4">pytorch::avgpool</a>(params, input[0])};</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;    }</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;  };</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;</div><div class="line"><a name="l00372"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html">  372</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_batch_norm2d.html">BatchNorm2d</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00374"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a24862bed65a92fe530ec5e7d0008d021">  374</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_batch_norm2d.html#a24862bed65a92fe530ec5e7d0008d021">gamma</a>;</div><div class="line"><a name="l00375"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a922f732e1115cfa4bdecb4162e607f5d">  375</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_batch_norm2d.html#a922f732e1115cfa4bdecb4162e607f5d">beta</a>;</div><div class="line"><a name="l00376"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#ada48f51ace7479c934b5910fd00ee2ca">  376</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_batch_norm2d.html#ada48f51ace7479c934b5910fd00ee2ca">running_mean</a>;</div><div class="line"><a name="l00377"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#ab401da951fb788f31aa02d58dc01d7a6">  377</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_batch_norm2d.html#ab401da951fb788f31aa02d58dc01d7a6">running_var</a>;</div><div class="line"><a name="l00378"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a91d1c372502d1d18f5fb8ce90866e8c0">  378</a></span>&#160;    <span class="keywordtype">float</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#a91d1c372502d1d18f5fb8ce90866e8c0">epsilon</a>;</div><div class="line"><a name="l00379"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a0f155750ee518f0284d59e31030ad6d9">  379</a></span>&#160;    <a class="code" href="classpycpp_1_1py__object.html">pycpp::py_object</a> <a class="code" href="classpytorch_1_1_batch_norm2d.html#a0f155750ee518f0284d59e31030ad6d9">utils</a>;</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00390"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#acad1a59f2edc4a810ff46458f4da8c82">  390</a></span>&#160;    <a class="code" href="classpytorch_1_1_batch_norm2d.html#acad1a59f2edc4a810ff46458f4da8c82">BatchNorm2d</a>(<span class="keyword">const</span> af::array &amp;gamma,</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;                <span class="keyword">const</span> af::array &amp;beta,</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;running_mean,</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;running_var,</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;epsilon = 1e-5) : gamma(gamma), beta(beta),</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;                                             running_mean(running_mean), running_var(running_var),</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;                                             epsilon(epsilon) {}</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;</div><div class="line"><a name="l00412"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a910802963973f5d64fb6d281635a1035">  412</a></span>&#160;    <a class="code" href="classpytorch_1_1_batch_norm2d.html#a910802963973f5d64fb6d281635a1035">BatchNorm2d</a>(<span class="keyword">const</span> std::string &amp;gamma_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;                <span class="keyword">const</span> std::vector&lt;int&gt; &amp;gamma_dims = {},</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;                <span class="keyword">const</span> std::string &amp;beta_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;                <span class="keyword">const</span> std::vector&lt;int&gt; &amp;beta_dims = {},</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;                <span class="keyword">const</span> std::string &amp;running_mean_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;                <span class="keyword">const</span> std::vector&lt;int&gt; &amp;running_mean_dims = {},</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;                <span class="keyword">const</span> std::string &amp;running_var_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;                <span class="keyword">const</span> std::vector&lt;int&gt; &amp;running_var_dims = {},</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;epsilon = 1e-5,</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;                <span class="keyword">const</span> std::string &amp;python_home = <span class="stringliteral">&quot;../scripts&quot;</span>) : utils(<span class="stringliteral">&quot;utils&quot;</span>, python_home), epsilon(epsilon){</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;      <span class="keywordflow">if</span> (!gamma_filename.empty()){</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;        this-&gt;add_gamma(gamma_filename, gamma_dims);</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;      }</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;      <span class="keywordflow">if</span> (!beta_filename.empty()){</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;        this-&gt;add_beta(beta_filename, beta_dims);</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;      }</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;      <span class="keywordflow">if</span> (!running_mean_filename.empty()){</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;        this-&gt;add_running_mean(running_mean_filename, running_mean_dims);</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;      }</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;      <span class="keywordflow">if</span> (!running_var_filename.empty()){</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;        this-&gt;add_running_var(running_var_filename, running_var_dims);</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;      }</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;    }</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;</div><div class="line"><a name="l00444"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#af29892810fccc85d2bc202c16c5d49fe">  444</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#af29892810fccc85d2bc202c16c5d49fe">add_gamma</a>(<span class="keyword">const</span> std::string &amp;gamma_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;                          <span class="keyword">const</span> std::vector&lt;int&gt; &amp;gamma_dims = {}){</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;      assert(gamma_dims.size() &gt; 0);</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;      PyObject *g = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(gamma_filename)});</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;      assert(g);</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;      gamma = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(g), gamma_dims.size(), gamma_dims);</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;    }</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;</div><div class="line"><a name="l00458"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a54664c298098621bc625e899c96f7af6">  458</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#a54664c298098621bc625e899c96f7af6">add_beta</a>(<span class="keyword">const</span> std::string &amp;beta_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;                          <span class="keyword">const</span> std::vector&lt;int&gt; &amp;beta_dims = {}){</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;      assert(beta_dims.size() &gt; 0);</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;      PyObject *b = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(beta_filename)});</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;      assert(b);</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;      beta = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(b), beta_dims.size(), beta_dims);</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;    }</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;</div><div class="line"><a name="l00472"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a44601eef2233bbf8cb6da963bcf1520e">  472</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#a44601eef2233bbf8cb6da963bcf1520e">add_running_mean</a>(<span class="keyword">const</span> std::string &amp;running_mean_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;                          <span class="keyword">const</span> std::vector&lt;int&gt; &amp;running_mean_dims = {}){</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;      assert(running_mean_dims.size() &gt; 0);</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;      PyObject *rm = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(running_mean_filename)});</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;      assert(rm);</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;      running_mean = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(rm), running_mean_dims.size(), running_mean_dims);</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;    }</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;</div><div class="line"><a name="l00486"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a1816381a3443fc87ee9b25efd0cfe6e3">  486</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_batch_norm2d.html#a1816381a3443fc87ee9b25efd0cfe6e3">add_running_var</a>(<span class="keyword">const</span> std::string &amp;running_var_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;                                 <span class="keyword">const</span> std::vector&lt;int&gt; &amp;running_var_dims = {}){</div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;      assert(running_var_dims.size() &gt; 0);</div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;      PyObject *rv = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(running_var_filename)});</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;      assert(rv);</div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;      running_var = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(rv), running_var_dims.size(), running_var_dims);</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;    }</div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;</div><div class="line"><a name="l00500"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#a708c9fbeed102fe07577f4d9321b2261">  500</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_batch_norm2d.html#a708c9fbeed102fe07577f4d9321b2261">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ae865095aad032ac1ea9516ae5361e0ab">batchnorm2d</a>(gamma, beta, running_mean, running_var, epsilon, input[0])};</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;    }</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;</div><div class="line"><a name="l00510"></a><span class="lineno"><a class="line" href="classpytorch_1_1_batch_norm2d.html#ab8a0e1cbc627b47c87a8cc5951b55e25">  510</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_batch_norm2d.html#ab8a0e1cbc627b47c87a8cc5951b55e25">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ae865095aad032ac1ea9516ae5361e0ab">batchnorm2d</a>(gamma, beta, running_mean, running_var, epsilon, input[0])};</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;    }</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;  };</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;</div><div class="line"><a name="l00524"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html">  524</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_linear.html">Linear</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00526"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a1ce5755565afc4f3de332e3f6836f3bd">  526</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_linear.html#a1ce5755565afc4f3de332e3f6836f3bd">weights</a>;</div><div class="line"><a name="l00527"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#ae2ec81120db6e196709dc11a67fc9ce8">  527</a></span>&#160;    af::array <a class="code" href="classpytorch_1_1_linear.html#ae2ec81120db6e196709dc11a67fc9ce8">bias</a>;</div><div class="line"><a name="l00528"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#ae1e4c23bdc871fa3df2d6fc1db4cf954">  528</a></span>&#160;    <a class="code" href="classpycpp_1_1py__object.html">pycpp::py_object</a> <a class="code" href="classpytorch_1_1_linear.html#ae1e4c23bdc871fa3df2d6fc1db4cf954">utils</a>;</div><div class="line"><a name="l00529"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#af77334f2b9d31c019e91834651dd5fe4">  529</a></span>&#160;    <span class="keywordtype">bool</span> <a class="code" href="classpytorch_1_1_linear.html#af77334f2b9d31c019e91834651dd5fe4">has_bias</a>;</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00538"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a47740884c0ce199daecd9958bd6b6ca3">  538</a></span>&#160;    <a class="code" href="classpytorch_1_1_linear.html#a47740884c0ce199daecd9958bd6b6ca3">Linear</a>(<span class="keyword">const</span> af::array &amp;weights,</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;           <span class="keyword">const</span> af::array &amp;bias) : weights(weights), bias(bias) { }</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;</div><div class="line"><a name="l00550"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#ad061ae2fec18baa95cc7b9b854b57f92">  550</a></span>&#160;    <a class="code" href="classpytorch_1_1_linear.html#ad061ae2fec18baa95cc7b9b854b57f92">Linear</a>(<span class="keyword">const</span> std::string &amp;weights_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;           <span class="keyword">const</span> std::vector&lt;int&gt; &amp;weights_dims = {},</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;           <span class="keyword">const</span> <span class="keywordtype">bool</span> has_bias = <span class="keyword">false</span>,</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;           <span class="keyword">const</span> std::string &amp;bias_filename = <span class="stringliteral">&quot;&quot;</span>,</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;           <span class="keyword">const</span> std::vector&lt;int&gt; &amp;bias_dims = {},</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;           <span class="keyword">const</span> std::string &amp;python_home = <span class="stringliteral">&quot;../scripts&quot;</span>) : utils(<span class="stringliteral">&quot;utils&quot;</span>, python_home), has_bias(has_bias) {</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;      <span class="keywordflow">if</span> (!weights_filename.empty()){</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;        this-&gt;add_weights(weights_filename, weights_dims);</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;      }</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;      <span class="keywordflow">if</span> (!bias_filename.empty() &amp;&amp; has_bias){</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;        this-&gt;add_bias(bias_filename, bias_dims);</div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;      }</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;    }</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;</div><div class="line"><a name="l00570"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#ac8bbc9c901cda2e77ac60abccf4de372">  570</a></span>&#160;    <a class="code" href="classpytorch_1_1_linear.html#ac8bbc9c901cda2e77ac60abccf4de372">Linear</a>(<span class="keyword">const</span> <a class="code" href="classpytorch_1_1_linear.html">Linear</a> &amp;other){</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;      weights = other.<a class="code" href="classpytorch_1_1_linear.html#a1ce5755565afc4f3de332e3f6836f3bd">weights</a>;</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;      bias = other.<a class="code" href="classpytorch_1_1_linear.html#ae2ec81120db6e196709dc11a67fc9ce8">bias</a>;</div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;    }</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;</div><div class="line"><a name="l00578"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a2b0abcb252baef05e13f648df24af1cf">  578</a></span>&#160;    <span class="keyword">virtual</span> <a class="code" href="classpytorch_1_1_linear.html#a2b0abcb252baef05e13f648df24af1cf">~Linear</a>() {}</div><div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;</div><div class="line"><a name="l00587"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a8cbffb226f756dfabc3fcbb80c075cef">  587</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_linear.html#a8cbffb226f756dfabc3fcbb80c075cef">add_weights</a>(<span class="keyword">const</span> std::string &amp;weights_filename,</div><div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;                            <span class="keyword">const</span> std::vector&lt;int&gt; &amp;weights_dims){</div><div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;      assert(weights_dims.size() &gt; 0);</div><div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;      PyObject *ws = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(weights_filename)});</div><div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;      assert(ws);</div><div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;      weights = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(ws), weights_dims.size(), weights_dims);</div><div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;    }</div><div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;</div><div class="line"><a name="l00602"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a4db382b11a3f91778797a6e940692d86">  602</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_linear.html#a4db382b11a3f91778797a6e940692d86">add_bias</a>(<span class="keyword">const</span> std::string &amp;bias_filename,</div><div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;                         <span class="keyword">const</span> std::vector&lt;int&gt; &amp;bias_dims){</div><div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;      assert(bias_dims.size() &gt; 0);</div><div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;      this-&gt;has_bias = <span class="keyword">true</span>;</div><div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;      PyObject *bs = utils(<span class="stringliteral">&quot;load_tensor&quot;</span>, {<a class="code" href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a>(bias_filename)});</div><div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;      assert(bs);</div><div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;      bias = <a class="code" href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">from_numpy</a>(reinterpret_cast&lt;PyArrayObject *&gt;(bs), bias_dims.size(), bias_dims);</div><div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;    }</div><div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;</div><div class="line"><a name="l00615"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a850c81192d2f73e96f42700b94091a57">  615</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">void</span> <a class="code" href="classpytorch_1_1_linear.html#a850c81192d2f73e96f42700b94091a57">set_has_bias</a>(<span class="keywordtype">bool</span> has_bias){</div><div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;      this-&gt;has_bias = has_bias;</div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;    }</div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;</div><div class="line"><a name="l00626"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a0b0318a61558f674bff2be8410da1fb5">  626</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_linear.html#a0b0318a61558f674bff2be8410da1fb5">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ad49eda1612a5d32ca493c4980741542e">linear</a>(input[0], weights, bias, this-&gt;has_bias)};</div><div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;    }</div><div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;</div><div class="line"><a name="l00637"></a><span class="lineno"><a class="line" href="classpytorch_1_1_linear.html#a6d86c19268604c3c35a7958bb55d0329">  637</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_linear.html#a6d86c19268604c3c35a7958bb55d0329">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ad49eda1612a5d32ca493c4980741542e">linear</a>(input[0], weights, bias, this-&gt;has_bias)};</div><div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;    }</div><div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;</div><div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;  };</div><div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;</div><div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;</div><div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;  <span class="comment">/* Branch - tested */</span></div><div class="line"><a name="l00647"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html">  647</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_branch.html">Branch</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00649"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#a911967d890c5619221dba7c77cfe2be0">  649</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_branch.html#a911967d890c5619221dba7c77cfe2be0">copies</a>;</div><div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00651"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#a20f7615a9da65d34b247ec79a801c06e">  651</a></span>&#160;    <a class="code" href="classpytorch_1_1_branch.html#a20f7615a9da65d34b247ec79a801c06e">Branch</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;copies) : copies(copies){}</div><div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;</div><div class="line"><a name="l00653"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#af70ee99c631a3c21d87ba0460130a437">  653</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_branch.html#af70ee99c631a3c21d87ba0460130a437">get_copies</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;      <span class="keywordflow">return</span> copies;</div><div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;    }</div><div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;</div><div class="line"><a name="l00657"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#ae0d6f620eab11534bb3262580c571c8f">  657</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_branch.html#ae0d6f620eab11534bb3262580c571c8f">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#aa1b0dc2ffe07685855199e859712f0a3">pytorch::copy_branch</a>(input[0], copies);</div><div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;    }</div><div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;</div><div class="line"><a name="l00661"></a><span class="lineno"><a class="line" href="classpytorch_1_1_branch.html#a56760a37afd47d7efe851abd51b33568">  661</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_branch.html#a56760a37afd47d7efe851abd51b33568">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#aa1b0dc2ffe07685855199e859712f0a3">pytorch::copy_branch</a>(input[0], copies);</div><div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;    }</div><div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;  };</div><div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;</div><div class="line"><a name="l00667"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html">  667</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_slice2.html">Slice2</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00669"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#ac204d3c7d94d2c60149e9c152795a33b">  669</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice2.html#ac204d3c7d94d2c60149e9c152795a33b">dim</a>;</div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00671"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#a2704991f0818c418d24408d7360f9d68">  671</a></span>&#160;    <a class="code" href="classpytorch_1_1_slice2.html#a2704991f0818c418d24408d7360f9d68">Slice2</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;</div><div class="line"><a name="l00673"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#aaa119a9771aaea730dd58ac6e45e8167">  673</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice2.html#aaa119a9771aaea730dd58ac6e45e8167">get_dim</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;      <span class="keywordflow">return</span> dim;</div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;    }</div><div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;</div><div class="line"><a name="l00677"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#aed74425320b96a734e7afcc1be2ac817">  677</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice2.html#aed74425320b96a734e7afcc1be2ac817">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 2, dim);</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;    }</div><div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;</div><div class="line"><a name="l00681"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice2.html#abcf999345ff5e740f379e3bb9fe93e9e">  681</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice2.html#abcf999345ff5e740f379e3bb9fe93e9e">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 2, dim);</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;    }</div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;</div><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;  };</div><div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;</div><div class="line"><a name="l00688"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html">  688</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_slice3.html">Slice3</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00690"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#ae0b8e103f4f37770a9ec0a6c079bc609">  690</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice3.html#ae0b8e103f4f37770a9ec0a6c079bc609">dim</a>;</div><div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00692"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#ab397c5ffb4526d2cd48c7ea64abc56b7">  692</a></span>&#160;    <a class="code" href="classpytorch_1_1_slice3.html#ab397c5ffb4526d2cd48c7ea64abc56b7">Slice3</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;</div><div class="line"><a name="l00694"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#a53fbbf80acc37d0d12520f583158461e">  694</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice3.html#a53fbbf80acc37d0d12520f583158461e">get_dim</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;      <span class="keywordflow">return</span> dim;</div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;    }</div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;</div><div class="line"><a name="l00698"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#af1a75e7f8473d605787c09320c51d63d">  698</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice3.html#af1a75e7f8473d605787c09320c51d63d">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 3, dim);</div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;    }</div><div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;</div><div class="line"><a name="l00702"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice3.html#a7405226a4261a588170c692ee7325cd8">  702</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice3.html#a7405226a4261a588170c692ee7325cd8">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 3, dim);</div><div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;    }</div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;</div><div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;  };</div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;</div><div class="line"><a name="l00709"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html">  709</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_slice4.html">Slice4</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;  <span class="keyword">private</span>:</div><div class="line"><a name="l00711"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#afa8dd7c24fa7fb6a8dab9568feea2b57">  711</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice4.html#afa8dd7c24fa7fb6a8dab9568feea2b57">dim</a>;</div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00713"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#a7c4b6e3a751b69ed1aaf13801aa989c0">  713</a></span>&#160;    <a class="code" href="classpytorch_1_1_slice4.html#a7c4b6e3a751b69ed1aaf13801aa989c0">Slice4</a>(<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;</div><div class="line"><a name="l00715"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#a227cb3c33ab5c5752bbe365943660bf8">  715</a></span>&#160;    <span class="keyword">inline</span> <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_slice4.html#a227cb3c33ab5c5752bbe365943660bf8">get_dim</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;      <span class="keywordflow">return</span> dim;</div><div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;    }</div><div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;</div><div class="line"><a name="l00719"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#a882cce34197fcb801aae899b3d7b6a91">  719</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice4.html#a882cce34197fcb801aae899b3d7b6a91">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 4, dim);</div><div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;    }</div><div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;</div><div class="line"><a name="l00723"></a><span class="lineno"><a class="line" href="classpytorch_1_1_slice4.html#a036ece17af42590a42f38e50633072de">  723</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_slice4.html#a036ece17af42590a42f38e50633072de">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a>(input[0], 4, dim);</div><div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;    }</div><div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;</div><div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;  };</div><div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;</div><div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;  <span class="comment">/* Concat2 - tested */</span></div><div class="line"><a name="l00731"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html">  731</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_concat2.html">Concat2</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00732"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html#ac8da916e9933b1dfcbede7db883cec3f">  732</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_concat2.html#ac8da916e9933b1dfcbede7db883cec3f">dim</a>;</div><div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00734"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html#a4295d2772036dd4c52c68cf4cc533f9c">  734</a></span>&#160;    <a class="code" href="classpytorch_1_1_concat2.html#a4295d2772036dd4c52c68cf4cc533f9c">Concat2</a> (<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160;</div><div class="line"><a name="l00736"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html#a6f45f28982b7a61093026c6715dfa9b5">  736</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat2.html#a6f45f28982b7a61093026c6715dfa9b5">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#af79090de8fcb96630036887e5f7b8ea7">pytorch::cat2</a>(input[0], input[1], dim)};</div><div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;    }</div><div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;</div><div class="line"><a name="l00740"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat2.html#ab7a24c04cf459171cd75876ee73032d0">  740</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat2.html#ab7a24c04cf459171cd75876ee73032d0">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#af79090de8fcb96630036887e5f7b8ea7">pytorch::cat2</a>(input[0], input[1], dim)};</div><div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;    }</div><div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160;  };</div><div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;</div><div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;  <span class="comment">/* Concat3 - tested */</span></div><div class="line"><a name="l00747"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html">  747</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_concat3.html">Concat3</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00748"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html#a2cbde9d6783a3dd1df871b575a5453e3">  748</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_concat3.html#a2cbde9d6783a3dd1df871b575a5453e3">dim</a>;</div><div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00750"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html#afca3a26b9eb7824646e34ea0071331ad">  750</a></span>&#160;    <a class="code" href="classpytorch_1_1_concat3.html#afca3a26b9eb7824646e34ea0071331ad">Concat3</a> (<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;</div><div class="line"><a name="l00752"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html#a3bea4ffd404197583dd5adecbc94e2f0">  752</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat3.html#a3bea4ffd404197583dd5adecbc94e2f0">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a9243e92d218fdf3718ab963e4005988e">pytorch::cat3</a>(input[0], input[1], input[2], dim)};</div><div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;    }</div><div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160;</div><div class="line"><a name="l00756"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat3.html#a57470086b64b3b7ff5c50e2e3cd8cebf">  756</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat3.html#a57470086b64b3b7ff5c50e2e3cd8cebf">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00757"></a><span class="lineno">  757</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a9243e92d218fdf3718ab963e4005988e">pytorch::cat3</a>(input[0], input[1], input[2], dim)};</div><div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;    }</div><div class="line"><a name="l00759"></a><span class="lineno">  759</span>&#160;  };</div><div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;</div><div class="line"><a name="l00761"></a><span class="lineno">  761</span>&#160;  <span class="comment">/* Concat4 - higher is not supported by arrayfire - tested */</span></div><div class="line"><a name="l00763"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html">  763</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_concat4.html">Concat4</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00764"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html#a8cd3acf88e40f3e3db0afd1341b43674">  764</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classpytorch_1_1_concat4.html#a8cd3acf88e40f3e3db0afd1341b43674">dim</a>;</div><div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00766"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html#af9ff578363eb1d53202e0614bc3c6aa1">  766</a></span>&#160;    <a class="code" href="classpytorch_1_1_concat4.html#af9ff578363eb1d53202e0614bc3c6aa1">Concat4</a> (<span class="keyword">const</span> <span class="keywordtype">int</span> &amp;dim) : dim(dim) {}</div><div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;</div><div class="line"><a name="l00768"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html#ad8115f840f7937f47849357f8f05a336">  768</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat4.html#ad8115f840f7937f47849357f8f05a336">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00769"></a><span class="lineno">  769</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ac48fbbcee5e49075953d6b3117eaa329">pytorch::cat4</a>(input[0], input[1], input[2], input[3], dim)};</div><div class="line"><a name="l00770"></a><span class="lineno">  770</span>&#160;    }</div><div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;</div><div class="line"><a name="l00772"></a><span class="lineno"><a class="line" href="classpytorch_1_1_concat4.html#aad8088bbad685a8d07ea11b2fa72d2ff">  772</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_concat4.html#aad8088bbad685a8d07ea11b2fa72d2ff">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00773"></a><span class="lineno">  773</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ac48fbbcee5e49075953d6b3117eaa329">pytorch::cat4</a>(input[0], input[1], input[2], input[3], dim)};</div><div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;    }</div><div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;  };</div><div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;</div><div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;  <span class="comment">/* Sigmoid - tested */</span></div><div class="line"><a name="l00779"></a><span class="lineno"><a class="line" href="classpytorch_1_1_sigmoid.html">  779</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_sigmoid.html">Sigmoid</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00781"></a><span class="lineno"><a class="line" href="classpytorch_1_1_sigmoid.html#a8e7e598171e919a5dd3dfd54ad38dbdc">  781</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_sigmoid.html#a8e7e598171e919a5dd3dfd54ad38dbdc">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ac61be684e3426c6f8c53dc794ccf3a70">pytorch::sigmoid</a>(input[0])};</div><div class="line"><a name="l00783"></a><span class="lineno">  783</span>&#160;    }</div><div class="line"><a name="l00784"></a><span class="lineno">  784</span>&#160;</div><div class="line"><a name="l00785"></a><span class="lineno"><a class="line" href="classpytorch_1_1_sigmoid.html#a272104b99e5c7dd6358b6ad66bac8334">  785</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_sigmoid.html#a272104b99e5c7dd6358b6ad66bac8334">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00786"></a><span class="lineno">  786</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#ac61be684e3426c6f8c53dc794ccf3a70">pytorch::sigmoid</a>(input[0])};</div><div class="line"><a name="l00787"></a><span class="lineno">  787</span>&#160;    }</div><div class="line"><a name="l00788"></a><span class="lineno">  788</span>&#160;  };</div><div class="line"><a name="l00789"></a><span class="lineno">  789</span>&#160;</div><div class="line"><a name="l00790"></a><span class="lineno">  790</span>&#160;  <span class="comment">/* Tanh - tested */</span></div><div class="line"><a name="l00792"></a><span class="lineno"><a class="line" href="classpytorch_1_1_tanh.html">  792</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_tanh.html">Tanh</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00793"></a><span class="lineno">  793</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00794"></a><span class="lineno"><a class="line" href="classpytorch_1_1_tanh.html#abebdcdc2a41b9cca18a30309af154600">  794</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_tanh.html#abebdcdc2a41b9cca18a30309af154600">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00795"></a><span class="lineno">  795</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#aaf715d23cef54abd1758cfaa439a0c0a">pytorch::tanh</a>(input[0])};</div><div class="line"><a name="l00796"></a><span class="lineno">  796</span>&#160;    }</div><div class="line"><a name="l00797"></a><span class="lineno">  797</span>&#160;</div><div class="line"><a name="l00798"></a><span class="lineno"><a class="line" href="classpytorch_1_1_tanh.html#a0d593d22d6b94e751d8f119626fb3e1f">  798</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_tanh.html#a0d593d22d6b94e751d8f119626fb3e1f">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00799"></a><span class="lineno">  799</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#aaf715d23cef54abd1758cfaa439a0c0a">pytorch::tanh</a>(input[0])};</div><div class="line"><a name="l00800"></a><span class="lineno">  800</span>&#160;    }</div><div class="line"><a name="l00801"></a><span class="lineno">  801</span>&#160;  };</div><div class="line"><a name="l00802"></a><span class="lineno">  802</span>&#160;</div><div class="line"><a name="l00803"></a><span class="lineno">  803</span>&#160;  <span class="comment">/* Hardtanh - tested */</span></div><div class="line"><a name="l00805"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html">  805</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_hardtanh.html">Hardtanh</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00806"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html#a973d1a366841c12b1c683e9d6794c9b8">  806</a></span>&#160;    <span class="keyword">const</span> <span class="keywordtype">float</span> <a class="code" href="classpytorch_1_1_hardtanh.html#a973d1a366841c12b1c683e9d6794c9b8">low</a>, high;</div><div class="line"><a name="l00807"></a><span class="lineno">  807</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00808"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html#a597d72b27db6b4647d91bdbef5b6a99c">  808</a></span>&#160;    <a class="code" href="classpytorch_1_1_hardtanh.html#a597d72b27db6b4647d91bdbef5b6a99c">Hardtanh</a>(<span class="keyword">const</span> <span class="keywordtype">float</span> &amp;low = 1.f, <span class="keyword">const</span> <span class="keywordtype">float</span> &amp;high = 1.f) : low(low), high(high) {}</div><div class="line"><a name="l00809"></a><span class="lineno">  809</span>&#160;</div><div class="line"><a name="l00810"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html#a0dddd311bb37d3bfb37f1ea45a1337ee">  810</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_hardtanh.html#a0dddd311bb37d3bfb37f1ea45a1337ee">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00811"></a><span class="lineno">  811</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a6b9e5bd40b9390dced2011dc1a2c6f27">pytorch::hardtanh</a>(input[0], low, high)};</div><div class="line"><a name="l00812"></a><span class="lineno">  812</span>&#160;    }</div><div class="line"><a name="l00813"></a><span class="lineno">  813</span>&#160;</div><div class="line"><a name="l00814"></a><span class="lineno"><a class="line" href="classpytorch_1_1_hardtanh.html#a9ac35a8c4dd94eb271e032605c73a3fb">  814</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_hardtanh.html#a9ac35a8c4dd94eb271e032605c73a3fb">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00815"></a><span class="lineno">  815</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a6b9e5bd40b9390dced2011dc1a2c6f27">pytorch::hardtanh</a>(input[0], low, high)};</div><div class="line"><a name="l00816"></a><span class="lineno">  816</span>&#160;    }</div><div class="line"><a name="l00817"></a><span class="lineno">  817</span>&#160;  };</div><div class="line"><a name="l00818"></a><span class="lineno">  818</span>&#160;</div><div class="line"><a name="l00819"></a><span class="lineno">  819</span>&#160;  <span class="comment">/* ReLU - tested */</span></div><div class="line"><a name="l00821"></a><span class="lineno"><a class="line" href="classpytorch_1_1_re_l_u.html">  821</a></span>&#160;  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_re_l_u.html">ReLU</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> {</div><div class="line"><a name="l00822"></a><span class="lineno">  822</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00823"></a><span class="lineno"><a class="line" href="classpytorch_1_1_re_l_u.html#a5488d7103355ed0f8f92aaea5364f3e2">  823</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_re_l_u.html#a5488d7103355ed0f8f92aaea5364f3e2">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00824"></a><span class="lineno">  824</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a8c699a8743e789f81ce5a9c0a119f557">pytorch::relu</a>(input[0])};</div><div class="line"><a name="l00825"></a><span class="lineno">  825</span>&#160;    }</div><div class="line"><a name="l00826"></a><span class="lineno">  826</span>&#160;</div><div class="line"><a name="l00827"></a><span class="lineno"><a class="line" href="classpytorch_1_1_re_l_u.html#afc78ace7d3c4eba28a4344b5dcf24fe9">  827</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_re_l_u.html#afc78ace7d3c4eba28a4344b5dcf24fe9">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00828"></a><span class="lineno">  828</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a8c699a8743e789f81ce5a9c0a119f557">pytorch::relu</a>(input[0])};</div><div class="line"><a name="l00829"></a><span class="lineno">  829</span>&#160;    }</div><div class="line"><a name="l00830"></a><span class="lineno">  830</span>&#160;  };</div><div class="line"><a name="l00831"></a><span class="lineno">  831</span>&#160;</div><div class="line"><a name="l00832"></a><span class="lineno">  832</span>&#160;  <span class="comment">// Softmax is not a stable operation so it&#39;s making testing hard...</span></div><div class="line"><a name="l00834"></a><span class="lineno"><a class="line" href="classpytorch_1_1_softmax.html">  834</a></span>&#160;<span class="comment"></span>  <span class="keyword">class </span><a class="code" href="classpytorch_1_1_softmax.html">Softmax</a> : <span class="keyword">public</span> <a class="code" href="classpytorch_1_1_layer.html">Layer</a> { <span class="comment">// SO SLOW GOOD LORD</span></div><div class="line"><a name="l00835"></a><span class="lineno">  835</span>&#160;  <span class="keyword">public</span>:</div><div class="line"><a name="l00836"></a><span class="lineno"><a class="line" href="classpytorch_1_1_softmax.html#a24909b8fdd420f9d0b6275dbcb3f8cc6">  836</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_softmax.html#a24909b8fdd420f9d0b6275dbcb3f8cc6">forward</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00837"></a><span class="lineno">  837</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a97f9016d270bdb685bf51d1833001797">pytorch::softmax</a>(input[0])};</div><div class="line"><a name="l00838"></a><span class="lineno">  838</span>&#160;    }</div><div class="line"><a name="l00839"></a><span class="lineno">  839</span>&#160;</div><div class="line"><a name="l00840"></a><span class="lineno"><a class="line" href="classpytorch_1_1_softmax.html#ad11cd227c282ff29eaafa26e491daaca">  840</a></span>&#160;    <span class="keyword">inline</span> std::vector&lt;af::array&gt; <a class="code" href="classpytorch_1_1_softmax.html#ad11cd227c282ff29eaafa26e491daaca">operator()</a>(<span class="keyword">const</span> std::vector&lt;af::array&gt; &amp;input){</div><div class="line"><a name="l00841"></a><span class="lineno">  841</span>&#160;      <span class="keywordflow">return</span> {<a class="code" href="namespacepytorch.html#a97f9016d270bdb685bf51d1833001797">pytorch::softmax</a>(input[0])};</div><div class="line"><a name="l00842"></a><span class="lineno">  842</span>&#160;    }</div><div class="line"><a name="l00843"></a><span class="lineno">  843</span>&#160;  };</div><div class="line"><a name="l00844"></a><span class="lineno">  844</span>&#160;</div><div class="line"><a name="l00845"></a><span class="lineno">  845</span>&#160;} <span class="comment">// pytorch</span></div><div class="line"><a name="l00846"></a><span class="lineno">  846</span>&#160;</div><div class="line"><a name="l00847"></a><span class="lineno">  847</span>&#160;</div><div class="line"><a name="l00848"></a><span class="lineno">  848</span>&#160;</div><div class="line"><a name="l00849"></a><span class="lineno">  849</span>&#160;<span class="preprocessor">#endif //PYTORCH_INFERENCE_LAYERS_HPP</span></div><div class="ttc" id="namespacepytorch_html_a97f9016d270bdb685bf51d1833001797"><div class="ttname"><a href="namespacepytorch.html#a97f9016d270bdb685bf51d1833001797">pytorch::softmax</a></div><div class="ttdeci">af::array softmax(const af::array &amp;a)</div><div class="ttdef"><b>Definition:</b> ops.hpp:333</div></div>
<div class="ttc" id="namespacepytorch_html_acb1b2c573dffc92bcb33e82ac1eb1ff8"><div class="ttname"><a href="namespacepytorch.html#acb1b2c573dffc92bcb33e82ac1eb1ff8">pytorch::from_numpy</a></div><div class="ttdeci">af::array from_numpy(PyArrayObject *array, int ndim, std::vector&lt; int &gt; dims)</div><div class="ttdoc">Converts a numpy array to an ArrayFire array. </div><div class="ttdef"><b>Definition:</b> utils.hpp:45</div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196a15d37568bf28ad3bce066ae5692e91de"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a15d37568bf28ad3bce066ae5692e91de">pytorch::w</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:48</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html_ad23e05cd109aaa2ddeaf132b0e5cc1f8"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html#ad23e05cd109aaa2ddeaf132b0e5cc1f8">pytorch::AvgPool2d::AvgPool2d</a></div><div class="ttdeci">AvgPool2d(const pooling_params_t &amp;params)</div><div class="ttdoc">Constructs the AvgPool2d layer. Requires pooling parameters that are functionally identical to the co...</div><div class="ttdef"><b>Definition:</b> layers.hpp:339</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_afeb76a74cb0f632466bc52dd12829ca5"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#afeb76a74cb0f632466bc52dd12829ca5">pytorch::Conv2d::add_bias</a></div><div class="ttdeci">void add_bias(const std::string &amp;bias_filename, const std::vector&lt; int &gt; &amp;bias_dims)</div><div class="ttdoc">Read in bias from a file given here if it wasn&amp;#39;t passed to the constructor. Overwrites current conten...</div><div class="ttdef"><b>Definition:</b> layers.hpp:200</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_a036ece17af42590a42f38e50633072de"><div class="ttname"><a href="classpytorch_1_1_slice4.html#a036ece17af42590a42f38e50633072de">pytorch::Slice4::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:723</div></div>
<div class="ttc" id="namespacepytorch_html_af79090de8fcb96630036887e5f7b8ea7"><div class="ttname"><a href="namespacepytorch.html#af79090de8fcb96630036887e5f7b8ea7">pytorch::cat2</a></div><div class="ttdeci">af::array cat2(const af::array &amp;input1, const af::array &amp;input2, const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> ops.hpp:200</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a2b0abcb252baef05e13f648df24af1cf"><div class="ttname"><a href="classpytorch_1_1_linear.html#a2b0abcb252baef05e13f648df24af1cf">pytorch::Linear::~Linear</a></div><div class="ttdeci">virtual ~Linear()</div><div class="ttdoc">Destructor - for now trivial, may need to take on some functionality. </div><div class="ttdef"><b>Definition:</b> layers.hpp:578</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_ac8bbc9c901cda2e77ac60abccf4de372"><div class="ttname"><a href="classpytorch_1_1_linear.html#ac8bbc9c901cda2e77ac60abccf4de372">pytorch::Linear::Linear</a></div><div class="ttdeci">Linear(const Linear &amp;other)</div><div class="ttdoc">Copy constructor, constructs another Linear object that is an exact copy of the argument. </div><div class="ttdef"><b>Definition:</b> layers.hpp:570</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_ab397c5ffb4526d2cd48c7ea64abc56b7"><div class="ttname"><a href="classpytorch_1_1_slice3.html#ab397c5ffb4526d2cd48c7ea64abc56b7">pytorch::Slice3::Slice3</a></div><div class="ttdeci">Slice3(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:692</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a922f732e1115cfa4bdecb4162e607f5d"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a922f732e1115cfa4bdecb4162e607f5d">pytorch::BatchNorm2d::beta</a></div><div class="ttdeci">af::array beta</div><div class="ttdef"><b>Definition:</b> layers.hpp:375</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a91d1c372502d1d18f5fb8ce90866e8c0"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a91d1c372502d1d18f5fb8ce90866e8c0">pytorch::BatchNorm2d::epsilon</a></div><div class="ttdeci">float epsilon</div><div class="ttdef"><b>Definition:</b> layers.hpp:378</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_a20f7615a9da65d34b247ec79a801c06e"><div class="ttname"><a href="classpytorch_1_1_branch.html#a20f7615a9da65d34b247ec79a801c06e">pytorch::Branch::Branch</a></div><div class="ttdeci">Branch(const int &amp;copies)</div><div class="ttdef"><b>Definition:</b> layers.hpp:651</div></div>
<div class="ttc" id="structpytorch_1_1conv__params__t_html"><div class="ttname"><a href="structpytorch_1_1conv__params__t.html">pytorch::conv_params_t</a></div><div class="ttdef"><b>Definition:</b> ops.hpp:44</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_aed74425320b96a734e7afcc1be2ac817"><div class="ttname"><a href="classpytorch_1_1_slice2.html#aed74425320b96a734e7afcc1be2ac817">pytorch::Slice2::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:677</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_ac596c3c020ec5ac7e324e6d32a7539bc"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#ac596c3c020ec5ac7e324e6d32a7539bc">pytorch::Conv2d::Conv2d</a></div><div class="ttdeci">Conv2d(const conv_params_t &amp;params, const std::string &amp;filters_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;filt_dims={}, const bool &amp;has_bias=false, const std::string &amp;bias_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;bias_dims={}, const std::string &amp;python_home=&quot;../scripts&quot;)</div><div class="ttdoc">Constructs a Conv2d object given the filenames and sizes of the requisite tensors. Also requires convolution parameters like the other constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:142</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html_ad8115f840f7937f47849357f8f05a336"><div class="ttname"><a href="classpytorch_1_1_concat4.html#ad8115f840f7937f47849357f8f05a336">pytorch::Concat4::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:768</div></div>
<div class="ttc" id="classpytorch_1_1_tanh_html"><div class="ttname"><a href="classpytorch_1_1_tanh.html">pytorch::Tanh</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:792</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html_ab7a24c04cf459171cd75876ee73032d0"><div class="ttname"><a href="classpytorch_1_1_concat2.html#ab7a24c04cf459171cd75876ee73032d0">pytorch::Concat2::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:740</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a44601eef2233bbf8cb6da963bcf1520e"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a44601eef2233bbf8cb6da963bcf1520e">pytorch::BatchNorm2d::add_running_mean</a></div><div class="ttdeci">void add_running_mean(const std::string &amp;running_mean_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;running_mean_dims={})</div><div class="ttdoc">Adds running_mean if it wasn&amp;#39;t added by the constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:472</div></div>
<div class="ttc" id="classpytorch_1_1_softmax_html_ad11cd227c282ff29eaafa26e491daaca"><div class="ttname"><a href="classpytorch_1_1_softmax.html#ad11cd227c282ff29eaafa26e491daaca">pytorch::Softmax::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:840</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a124b1cab460114aa17dfe76ed1b46fce"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a124b1cab460114aa17dfe76ed1b46fce">pytorch::Conv2d::params</a></div><div class="ttdeci">conv_params_t params</div><div class="ttdef"><b>Definition:</b> layers.hpp:115</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_ab8a0e1cbc627b47c87a8cc5951b55e25"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#ab8a0e1cbc627b47c87a8cc5951b55e25">pytorch::BatchNorm2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Applies the forward pass of batch normalization. </div><div class="ttdef"><b>Definition:</b> layers.hpp:510</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html_a1904e62fdaee1476b737a364b5156be7"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html#a1904e62fdaee1476b737a364b5156be7">pytorch::AvgPool2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forwards pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:347</div></div>
<div class="ttc" id="namespacepytorch_html_a12e2103bef62222f09265c609d047299"><div class="ttname"><a href="namespacepytorch.html#a12e2103bef62222f09265c609d047299">pytorch::unpool</a></div><div class="ttdeci">af::array unpool(const pooling_params_t &amp;params, const af::array &amp;input, const af::array &amp;indices)</div><div class="ttdef"><b>Definition:</b> ops.hpp:263</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html"><div class="ttname"><a href="classpytorch_1_1_branch.html">pytorch::Branch</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:647</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html">pytorch::MaxPool2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:241</div></div>
<div class="ttc" id="py__object_8hpp_html"><div class="ttname"><a href="py__object_8hpp.html">py_object.hpp</a></div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_af1a75e7f8473d605787c09320c51d63d"><div class="ttname"><a href="classpytorch_1_1_slice3.html#af1a75e7f8473d605787c09320c51d63d">pytorch::Slice3::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:698</div></div>
<div class="ttc" id="namespacepytorch_html_a94ec836f5c6229b0b05a2d5d0c083861"><div class="ttname"><a href="namespacepytorch.html#a94ec836f5c6229b0b05a2d5d0c083861">pytorch::conv2d</a></div><div class="ttdeci">af::array conv2d(const conv_params_t &amp;params, const af::array &amp;input, const af::array &amp;filters, const af::array &amp;bias, const bool &amp;has_bias)</div><div class="ttdoc">Performs convolution given exported pytorch filters. </div><div class="ttdef"><b>Definition:</b> ops.hpp:72</div></div>
<div class="ttc" id="classpytorch_1_1_skip_html"><div class="ttname"><a href="classpytorch_1_1_skip.html">pytorch::Skip</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:82</div></div>
<div class="ttc" id="classpytorch_1_1_tanh_html_abebdcdc2a41b9cca18a30309af154600"><div class="ttname"><a href="classpytorch_1_1_tanh.html#abebdcdc2a41b9cca18a30309af154600">pytorch::Tanh::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:794</div></div>
<div class="ttc" id="namespacepytorch_html_ae865095aad032ac1ea9516ae5361e0ab"><div class="ttname"><a href="namespacepytorch.html#ae865095aad032ac1ea9516ae5361e0ab">pytorch::batchnorm2d</a></div><div class="ttdeci">af::array batchnorm2d(const af::array &amp;gamma, const af::array &amp;beta, const af::array &amp;running_mean, const af::array &amp;running_variance, const float &amp;epsilon, const af::array &amp;input)</div><div class="ttdef"><b>Definition:</b> ops.hpp:222</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_acad1a59f2edc4a810ff46458f4da8c82"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#acad1a59f2edc4a810ff46458f4da8c82">pytorch::BatchNorm2d::BatchNorm2d</a></div><div class="ttdeci">BatchNorm2d(const af::array &amp;gamma, const af::array &amp;beta, const float &amp;running_mean, const float &amp;running_var, const float &amp;epsilon=1e-5)</div><div class="ttdoc">Constructs a BatchNorm2d object. </div><div class="ttdef"><b>Definition:</b> layers.hpp:390</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_a7405226a4261a588170c692ee7325cd8"><div class="ttname"><a href="classpytorch_1_1_slice3.html#a7405226a4261a588170c692ee7325cd8">pytorch::Slice3::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:702</div></div>
<div class="ttc" id="classpytorch_1_1_softmax_html_a24909b8fdd420f9d0b6275dbcb3f8cc6"><div class="ttname"><a href="classpytorch_1_1_softmax.html#a24909b8fdd420f9d0b6275dbcb3f8cc6">pytorch::Softmax::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:836</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a24862bed65a92fe530ec5e7d0008d021"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a24862bed65a92fe530ec5e7d0008d021">pytorch::BatchNorm2d::gamma</a></div><div class="ttdeci">af::array gamma</div><div class="ttdef"><b>Definition:</b> layers.hpp:374</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html">pytorch::Hardtanh</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:805</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_a911967d890c5619221dba7c77cfe2be0"><div class="ttname"><a href="classpytorch_1_1_branch.html#a911967d890c5619221dba7c77cfe2be0">pytorch::Branch::copies</a></div><div class="ttdeci">int copies</div><div class="ttdef"><b>Definition:</b> layers.hpp:649</div></div>
<div class="ttc" id="utils_8hpp_html"><div class="ttname"><a href="utils_8hpp.html">utils.hpp</a></div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196a1f250f3998835bb50ff8608dead82418"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a1f250f3998835bb50ff8608dead82418">pytorch::h</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:47</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a6849f3a4850596f32f05b51273ea4eb3"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a6849f3a4850596f32f05b51273ea4eb3">pytorch::MaxPool2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forward pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:274</div></div>
<div class="ttc" id="classpytorch_1_1_re_l_u_html_a5488d7103355ed0f8f92aaea5364f3e2"><div class="ttname"><a href="classpytorch_1_1_re_l_u.html#a5488d7103355ed0f8f92aaea5364f3e2">pytorch::ReLU::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:823</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_ab401da951fb788f31aa02d58dc01d7a6"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#ab401da951fb788f31aa02d58dc01d7a6">pytorch::BatchNorm2d::running_var</a></div><div class="ttdeci">af::array running_var</div><div class="ttdef"><b>Definition:</b> layers.hpp:377</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_ae2ec81120db6e196709dc11a67fc9ce8"><div class="ttname"><a href="classpytorch_1_1_linear.html#ae2ec81120db6e196709dc11a67fc9ce8">pytorch::Linear::bias</a></div><div class="ttdeci">af::array bias</div><div class="ttdef"><b>Definition:</b> layers.hpp:527</div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196a73a50f78ad527d77d9f062bf071de1b5"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a73a50f78ad527d77d9f062bf071de1b5">pytorch::k</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:46</div></div>
<div class="ttc" id="namespacepytorch_html_a78a38423eda0d20c5b3c61c69a0ce8c4"><div class="ttname"><a href="namespacepytorch.html#a78a38423eda0d20c5b3c61c69a0ce8c4">pytorch::avgpool</a></div><div class="ttdeci">af::array avgpool(const pooling_params_t &amp;params, const af::array &amp;input)</div><div class="ttdef"><b>Definition:</b> ops.hpp:296</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html"><div class="ttname"><a href="classpytorch_1_1_linear.html">pytorch::Linear</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:524</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html_af9ff578363eb1d53202e0614bc3c6aa1"><div class="ttname"><a href="classpytorch_1_1_concat4.html#af9ff578363eb1d53202e0614bc3c6aa1">pytorch::Concat4::Concat4</a></div><div class="ttdeci">Concat4(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:766</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html_a57470086b64b3b7ff5c50e2e3cd8cebf"><div class="ttname"><a href="classpytorch_1_1_concat3.html#a57470086b64b3b7ff5c50e2e3cd8cebf">pytorch::Concat3::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:756</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_a2704991f0818c418d24408d7360f9d68"><div class="ttname"><a href="classpytorch_1_1_slice2.html#a2704991f0818c418d24408d7360f9d68">pytorch::Slice2::Slice2</a></div><div class="ttdeci">Slice2(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:671</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a5f2ea435fea042c0677ecd665de1405b"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a5f2ea435fea042c0677ecd665de1405b">pytorch::MaxPool2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forward pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:264</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html_a2cbde9d6783a3dd1df871b575a5453e3"><div class="ttname"><a href="classpytorch_1_1_concat3.html#a2cbde9d6783a3dd1df871b575a5453e3">pytorch::Concat3::dim</a></div><div class="ttdeci">int dim</div><div class="ttdef"><b>Definition:</b> layers.hpp:748</div></div>
<div class="ttc" id="classpycpp_1_1py__object_html"><div class="ttname"><a href="classpycpp_1_1py__object.html">pycpp::py_object</a></div><div class="ttdef"><b>Definition:</b> py_object.hpp:488</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html_a3bea4ffd404197583dd5adecbc94e2f0"><div class="ttname"><a href="classpytorch_1_1_concat3.html#a3bea4ffd404197583dd5adecbc94e2f0">pytorch::Concat3::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:752</div></div>
<div class="ttc" id="classpytorch_1_1_max_unpool2d_html"><div class="ttname"><a href="classpytorch_1_1_max_unpool2d.html">pytorch::MaxUnpool2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:287</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a0b0318a61558f674bff2be8410da1fb5"><div class="ttname"><a href="classpytorch_1_1_linear.html#a0b0318a61558f674bff2be8410da1fb5">pytorch::Linear::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function, takes data and performs the Linear operation using the already-initialized weights ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:626</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_aaa119a9771aaea730dd58ac6e45e8167"><div class="ttname"><a href="classpytorch_1_1_slice2.html#aaa119a9771aaea730dd58ac6e45e8167">pytorch::Slice2::get_dim</a></div><div class="ttdeci">int get_dim() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:673</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html_a9ac35a8c4dd94eb271e032605c73a3fb"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html#a9ac35a8c4dd94eb271e032605c73a3fb">pytorch::Hardtanh::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:814</div></div>
<div class="ttc" id="classpytorch_1_1_skip_html_ab3833af82d8d8b7579b2515d6e06e5ce"><div class="ttname"><a href="classpytorch_1_1_skip.html#ab3833af82d8d8b7579b2515d6e06e5ce">pytorch::Skip::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">No-op forward. </div><div class="ttdef"><b>Definition:</b> layers.hpp:89</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a54285d3747c0e5db24dbbd86245fd4eb"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a54285d3747c0e5db24dbbd86245fd4eb">pytorch::Conv2d::filters</a></div><div class="ttdeci">af::array filters</div><div class="ttdef"><b>Definition:</b> layers.hpp:113</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a3251f7f29fd9ef9c1d096301f3d120c3"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a3251f7f29fd9ef9c1d096301f3d120c3">pytorch::MaxPool2d::indices</a></div><div class="ttdeci">af::array indices</div><div class="ttdef"><b>Definition:</b> layers.hpp:244</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html_a8cd3acf88e40f3e3db0afd1341b43674"><div class="ttname"><a href="classpytorch_1_1_concat4.html#a8cd3acf88e40f3e3db0afd1341b43674">pytorch::Concat4::dim</a></div><div class="ttdeci">int dim</div><div class="ttdef"><b>Definition:</b> layers.hpp:764</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_af2ca65a5d5e3272b0f8963163d846924"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#af2ca65a5d5e3272b0f8963163d846924">pytorch::Conv2d::utils</a></div><div class="ttdeci">pycpp::py_object utils</div><div class="ttdef"><b>Definition:</b> layers.hpp:116</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_ad59f5c6c9fd3a6a238cfa50fa94e4019"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#ad59f5c6c9fd3a6a238cfa50fa94e4019">pytorch::Conv2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function, takes data and performs the Conv2d operation using the already-initialized filters ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:226</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a8c601902ed93f0afa8ab61e62110f19f"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a8c601902ed93f0afa8ab61e62110f19f">pytorch::MaxPool2d::MaxPool2d</a></div><div class="ttdeci">MaxPool2d(const pooling_params_t &amp;params)</div><div class="ttdoc">Constructs the MaxPool2d layer. Requires pooling parameters that are functionally equivalent to the c...</div><div class="ttdef"><b>Definition:</b> layers.hpp:252</div></div>
<div class="ttc" id="classpytorch_1_1_re_l_u_html_afc78ace7d3c4eba28a4344b5dcf24fe9"><div class="ttname"><a href="classpytorch_1_1_re_l_u.html#afc78ace7d3c4eba28a4344b5dcf24fe9">pytorch::ReLU::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:827</div></div>
<div class="ttc" id="classpytorch_1_1_max_unpool2d_html_af0b4cba5f7c22bc03b0d32f39ff6423f"><div class="ttname"><a href="classpytorch_1_1_max_unpool2d.html#af0b4cba5f7c22bc03b0d32f39ff6423f">pytorch::MaxUnpool2d::MaxUnpool2d</a></div><div class="ttdeci">MaxUnpool2d(const pooling_params_t &amp;params, const MaxPool2d *mp_ref)</div><div class="ttdoc">Constructs the MaxUnpool2d layer. Requires pooling parameters that are functionally equivalent to the...</div><div class="ttdef"><b>Definition:</b> layers.hpp:298</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_ae0d6f620eab11534bb3262580c571c8f"><div class="ttname"><a href="classpytorch_1_1_branch.html#ae0d6f620eab11534bb3262580c571c8f">pytorch::Branch::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:657</div></div>
<div class="ttc" id="classpytorch_1_1_layer_html_a7a766ac20be5e818e497e6f2f05a2c8d"><div class="ttname"><a href="classpytorch_1_1_layer.html#a7a766ac20be5e818e497e6f2f05a2c8d">pytorch::Layer::operator()</a></div><div class="ttdeci">virtual std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)=0</div><div class="ttdoc">Forward function for this layer. </div></div>
<div class="ttc" id="classpytorch_1_1_layer_html_a1abb45857b18f70a9a95ae16a69f968d"><div class="ttname"><a href="classpytorch_1_1_layer.html#a1abb45857b18f70a9a95ae16a69f968d">pytorch::Layer::forward</a></div><div class="ttdeci">virtual std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)=0</div><div class="ttdoc">Forward function for this layer. </div></div>
<div class="ttc" id="namespacepytorch_html_ac48fbbcee5e49075953d6b3117eaa329"><div class="ttname"><a href="namespacepytorch.html#ac48fbbcee5e49075953d6b3117eaa329">pytorch::cat4</a></div><div class="ttdeci">af::array cat4(const af::array &amp;input1, const af::array &amp;input2, const af::array &amp;input3, const af::array &amp;input4, const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> ops.hpp:213</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a6d86c19268604c3c35a7958bb55d0329"><div class="ttname"><a href="classpytorch_1_1_linear.html#a6d86c19268604c3c35a7958bb55d0329">pytorch::Linear::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function, takes data and performs the Linear operation using the already-initialized weights ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:637</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a0f155750ee518f0284d59e31030ad6d9"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a0f155750ee518f0284d59e31030ad6d9">pytorch::BatchNorm2d::utils</a></div><div class="ttdeci">pycpp::py_object utils</div><div class="ttdef"><b>Definition:</b> layers.hpp:379</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_a56760a37afd47d7efe851abd51b33568"><div class="ttname"><a href="classpytorch_1_1_branch.html#a56760a37afd47d7efe851abd51b33568">pytorch::Branch::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:661</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html"><div class="ttname"><a href="classpytorch_1_1_slice4.html">pytorch::Slice4</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:709</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_ae1e4c23bdc871fa3df2d6fc1db4cf954"><div class="ttname"><a href="classpytorch_1_1_linear.html#ae1e4c23bdc871fa3df2d6fc1db4cf954">pytorch::Linear::utils</a></div><div class="ttdeci">pycpp::py_object utils</div><div class="ttdef"><b>Definition:</b> layers.hpp:528</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a850c81192d2f73e96f42700b94091a57"><div class="ttname"><a href="classpytorch_1_1_linear.html#a850c81192d2f73e96f42700b94091a57">pytorch::Linear::set_has_bias</a></div><div class="ttdeci">void set_has_bias(bool has_bias)</div><div class="ttdoc">Sets whether or not this layer has bias. If no, then this should be called. Otherwise, it&amp;#39;s unnecessary. </div><div class="ttdef"><b>Definition:</b> layers.hpp:615</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a708c9fbeed102fe07577f4d9321b2261"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a708c9fbeed102fe07577f4d9321b2261">pytorch::BatchNorm2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Applies the forward pass of batch normalization. </div><div class="ttdef"><b>Definition:</b> layers.hpp:500</div></div>
<div class="ttc" id="namespacepytorch_html_a6b9e5bd40b9390dced2011dc1a2c6f27"><div class="ttname"><a href="namespacepytorch.html#a6b9e5bd40b9390dced2011dc1a2c6f27">pytorch::hardtanh</a></div><div class="ttdeci">af::array hardtanh(const af::array &amp;a, const float &amp;low=1.f, const float &amp;high=1.f)</div><div class="ttdef"><b>Definition:</b> ops.hpp:317</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html_aad8088bbad685a8d07ea11b2fa72d2ff"><div class="ttname"><a href="classpytorch_1_1_concat4.html#aad8088bbad685a8d07ea11b2fa72d2ff">pytorch::Concat4::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:772</div></div>
<div class="ttc" id="namespacepycpp_html_a7589e2bbb5161df0a000a2e0026e6e95"><div class="ttname"><a href="namespacepycpp.html#a7589e2bbb5161df0a000a2e0026e6e95">pycpp::to_python</a></div><div class="ttdeci">PyObject * to_python(const std::vector&lt; int &gt; &amp;vec)</div><div class="ttdoc">Takes a vector to a python list. </div><div class="ttdef"><b>Definition:</b> py_object.hpp:81</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a54664c298098621bc625e899c96f7af6"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a54664c298098621bc625e899c96f7af6">pytorch::BatchNorm2d::add_beta</a></div><div class="ttdeci">void add_beta(const std::string &amp;beta_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;beta_dims={})</div><div class="ttdoc">Adds beta if it wasn&amp;#39;t added by the constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:458</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html"><div class="ttname"><a href="classpytorch_1_1_concat2.html">pytorch::Concat2</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:731</div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196a72642ee422e2c907c36ca4762478cb3d"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196a72642ee422e2c907c36ca4762478cb3d">pytorch::n</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:45</div></div>
<div class="ttc" id="namespacepytorch_html_a8c699a8743e789f81ce5a9c0a119f557"><div class="ttname"><a href="namespacepytorch.html#a8c699a8743e789f81ce5a9c0a119f557">pytorch::relu</a></div><div class="ttdeci">af::array relu(const af::array &amp;a)</div><div class="ttdef"><b>Definition:</b> ops.hpp:325</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_ac7173111158536b89905c320e53cc4b8"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#ac7173111158536b89905c320e53cc4b8">pytorch::Conv2d::add_filters</a></div><div class="ttdeci">void add_filters(const ::std::string &amp;filters_filename, const std::vector&lt; int &gt; &amp;filt_dims)</div><div class="ttdoc">Read in filters from a file given here if it wasn&amp;#39;t passed to the constructor. Overwrites current con...</div><div class="ttdef"><b>Definition:</b> layers.hpp:185</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html_a6f45f28982b7a61093026c6715dfa9b5"><div class="ttname"><a href="classpytorch_1_1_concat2.html#a6f45f28982b7a61093026c6715dfa9b5">pytorch::Concat2::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:736</div></div>
<div class="ttc" id="namespacepytorch_html_ad49eda1612a5d32ca493c4980741542e"><div class="ttname"><a href="namespacepytorch.html#ad49eda1612a5d32ca493c4980741542e">pytorch::linear</a></div><div class="ttdeci">af::array linear(const af::array &amp;input, const af::array &amp;weight, const af::array &amp;bias, const bool &amp;has_bias)</div><div class="ttdoc">Performs the linear transformation y = Wx + b. </div><div class="ttdef"><b>Definition:</b> ops.hpp:133</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_af77334f2b9d31c019e91834651dd5fe4"><div class="ttname"><a href="classpytorch_1_1_linear.html#af77334f2b9d31c019e91834651dd5fe4">pytorch::Linear::has_bias</a></div><div class="ttdeci">bool has_bias</div><div class="ttdef"><b>Definition:</b> layers.hpp:529</div></div>
<div class="ttc" id="classpytorch_1_1_max_unpool2d_html_a81abe04136f9c82a92e553ea354968ed"><div class="ttname"><a href="classpytorch_1_1_max_unpool2d.html#a81abe04136f9c82a92e553ea354968ed">pytorch::MaxUnpool2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forward pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:316</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_abcf999345ff5e740f379e3bb9fe93e9e"><div class="ttname"><a href="classpytorch_1_1_slice2.html#abcf999345ff5e740f379e3bb9fe93e9e">pytorch::Slice2::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:681</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html"><div class="ttname"><a href="classpytorch_1_1_conv2d.html">pytorch::Conv2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:111</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html_afca3a26b9eb7824646e34ea0071331ad"><div class="ttname"><a href="classpytorch_1_1_concat3.html#afca3a26b9eb7824646e34ea0071331ad">pytorch::Concat3::Concat3</a></div><div class="ttdeci">Concat3(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:750</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_a227cb3c33ab5c5752bbe365943660bf8"><div class="ttname"><a href="classpytorch_1_1_slice4.html#a227cb3c33ab5c5752bbe365943660bf8">pytorch::Slice4::get_dim</a></div><div class="ttdeci">int get_dim() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:715</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html">pytorch::BatchNorm2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:372</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html_a973d1a366841c12b1c683e9d6794c9b8"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html#a973d1a366841c12b1c683e9d6794c9b8">pytorch::Hardtanh::low</a></div><div class="ttdeci">const float low</div><div class="ttdef"><b>Definition:</b> layers.hpp:806</div></div>
<div class="ttc" id="namespacepytorch_html_ac61be684e3426c6f8c53dc794ccf3a70"><div class="ttname"><a href="namespacepytorch.html#ac61be684e3426c6f8c53dc794ccf3a70">pytorch::sigmoid</a></div><div class="ttdeci">af::array sigmoid(const af::array &amp;a)</div><div class="ttdef"><b>Definition:</b> ops.hpp:313</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_a7c4b6e3a751b69ed1aaf13801aa989c0"><div class="ttname"><a href="classpytorch_1_1_slice4.html#a7c4b6e3a751b69ed1aaf13801aa989c0">pytorch::Slice4::Slice4</a></div><div class="ttdeci">Slice4(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:713</div></div>
<div class="ttc" id="classpytorch_1_1_re_l_u_html"><div class="ttname"><a href="classpytorch_1_1_re_l_u.html">pytorch::ReLU</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:821</div></div>
<div class="ttc" id="classpytorch_1_1_max_unpool2d_html_a6b52ffb75b96367f46135a524fdd8a53"><div class="ttname"><a href="classpytorch_1_1_max_unpool2d.html#a6b52ffb75b96367f46135a524fdd8a53">pytorch::MaxUnpool2d::mp_ref</a></div><div class="ttdeci">const MaxPool2d * mp_ref</div><div class="ttdef"><b>Definition:</b> layers.hpp:290</div></div>
<div class="ttc" id="namespacepytorch_html_aaf715d23cef54abd1758cfaa439a0c0a"><div class="ttname"><a href="namespacepytorch.html#aaf715d23cef54abd1758cfaa439a0c0a">pytorch::tanh</a></div><div class="ttdeci">af::array tanh(const af::array &amp;a)</div><div class="ttdef"><b>Definition:</b> ops.hpp:321</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a01ce0020e17604df233fccdd235d265f"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a01ce0020e17604df233fccdd235d265f">pytorch::MaxPool2d::params</a></div><div class="ttdeci">pooling_params_t params</div><div class="ttdef"><b>Definition:</b> layers.hpp:243</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_a882cce34197fcb801aae899b3d7b6a91"><div class="ttname"><a href="classpytorch_1_1_slice4.html#a882cce34197fcb801aae899b3d7b6a91">pytorch::Slice4::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:719</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a625e155c4c0e9aafa899ddcba2ce5fc6"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a625e155c4c0e9aafa899ddcba2ce5fc6">pytorch::Conv2d::Conv2d</a></div><div class="ttdeci">Conv2d(const Conv2d &amp;other)</div><div class="ttdoc">Copy constructor, constructs a Conv2d object that is exactly a copy of the argument. </div><div class="ttdef"><b>Definition:</b> layers.hpp:167</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html">pytorch::AvgPool2d</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:329</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html_a1256dba0f7f4207327a70573687aa66b"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html#a1256dba0f7f4207327a70573687aa66b">pytorch::AvgPool2d::params</a></div><div class="ttdeci">pooling_params_t params</div><div class="ttdef"><b>Definition:</b> layers.hpp:331</div></div>
<div class="ttc" id="namespacepytorch_html"><div class="ttname"><a href="namespacepytorch.html">pytorch</a></div><div class="ttdef"><b>Definition:</b> inference_engine.hpp:37</div></div>
<div class="ttc" id="classpytorch_1_1_concat4_html"><div class="ttname"><a href="classpytorch_1_1_concat4.html">pytorch::Concat4</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:763</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a953a1db977476c1b7d963459a63b9034"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a953a1db977476c1b7d963459a63b9034">pytorch::Conv2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function, takes data and performs the Conv2d operation using the already-initialized filters ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:215</div></div>
<div class="ttc" id="classpytorch_1_1_sigmoid_html_a272104b99e5c7dd6358b6ad66bac8334"><div class="ttname"><a href="classpytorch_1_1_sigmoid.html#a272104b99e5c7dd6358b6ad66bac8334">pytorch::Sigmoid::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:785</div></div>
<div class="ttc" id="classpytorch_1_1_skip_html_a968c864ee798307240bd9ea3d17156c3"><div class="ttname"><a href="classpytorch_1_1_skip.html#a968c864ee798307240bd9ea3d17156c3">pytorch::Skip::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">No-op forward. </div><div class="ttdef"><b>Definition:</b> layers.hpp:98</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a8cbffb226f756dfabc3fcbb80c075cef"><div class="ttname"><a href="classpytorch_1_1_linear.html#a8cbffb226f756dfabc3fcbb80c075cef">pytorch::Linear::add_weights</a></div><div class="ttdeci">void add_weights(const std::string &amp;weights_filename, const std::vector&lt; int &gt; &amp;weights_dims)</div><div class="ttdoc">Read in weights from a file given here if it wasn&amp;#39;t passed to the constructor. Overwrites current con...</div><div class="ttdef"><b>Definition:</b> layers.hpp:587</div></div>
<div class="ttc" id="classpytorch_1_1_slice4_html_afa8dd7c24fa7fb6a8dab9568feea2b57"><div class="ttname"><a href="classpytorch_1_1_slice4.html#afa8dd7c24fa7fb6a8dab9568feea2b57">pytorch::Slice4::dim</a></div><div class="ttdeci">int dim</div><div class="ttdef"><b>Definition:</b> layers.hpp:711</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_ad061ae2fec18baa95cc7b9b854b57f92"><div class="ttname"><a href="classpytorch_1_1_linear.html#ad061ae2fec18baa95cc7b9b854b57f92">pytorch::Linear::Linear</a></div><div class="ttdeci">Linear(const std::string &amp;weights_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;weights_dims={}, const bool has_bias=false, const std::string &amp;bias_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;bias_dims={}, const std::string &amp;python_home=&quot;../scripts&quot;)</div><div class="ttdoc">Constructs a Linear object given the filenames and sizes of the requisite tensors. </div><div class="ttdef"><b>Definition:</b> layers.hpp:550</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html_a597d72b27db6b4647d91bdbef5b6a99c"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html#a597d72b27db6b4647d91bdbef5b6a99c">pytorch::Hardtanh::Hardtanh</a></div><div class="ttdeci">Hardtanh(const float &amp;low=1.f, const float &amp;high=1.f)</div><div class="ttdef"><b>Definition:</b> layers.hpp:808</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html_ac204d3c7d94d2c60149e9c152795a33b"><div class="ttname"><a href="classpytorch_1_1_slice2.html#ac204d3c7d94d2c60149e9c152795a33b">pytorch::Slice2::dim</a></div><div class="ttdeci">int dim</div><div class="ttdef"><b>Definition:</b> layers.hpp:669</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html"><div class="ttname"><a href="classpytorch_1_1_slice3.html">pytorch::Slice3</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:688</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a5e7eb9604dbc94ca62edd04ec8944faf"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a5e7eb9604dbc94ca62edd04ec8944faf">pytorch::Conv2d::~Conv2d</a></div><div class="ttdeci">virtual ~Conv2d()</div><div class="ttdoc">Destructor - for now trivial, may need to take on some functionality. </div><div class="ttdef"><b>Definition:</b> layers.hpp:176</div></div>
<div class="ttc" id="classpytorch_1_1_tanh_html_a0d593d22d6b94e751d8f119626fb3e1f"><div class="ttname"><a href="classpytorch_1_1_tanh.html#a0d593d22d6b94e751d8f119626fb3e1f">pytorch::Tanh::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:798</div></div>
<div class="ttc" id="namespacepytorch_html_a72df22b8266ef90d0b94983f84ad52cb"><div class="ttname"><a href="namespacepytorch.html#a72df22b8266ef90d0b94983f84ad52cb">pytorch::split_branch</a></div><div class="ttdeci">std::vector&lt; af::array &gt; split_branch(const af::array &amp;input, const int &amp;slices, const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> ops.hpp:166</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html_a4295d2772036dd4c52c68cf4cc533f9c"><div class="ttname"><a href="classpytorch_1_1_concat2.html#a4295d2772036dd4c52c68cf4cc533f9c">pytorch::Concat2::Concat2</a></div><div class="ttdeci">Concat2(const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> layers.hpp:734</div></div>
<div class="ttc" id="classpytorch_1_1_hardtanh_html_a0dddd311bb37d3bfb37f1ea45a1337ee"><div class="ttname"><a href="classpytorch_1_1_hardtanh.html#a0dddd311bb37d3bfb37f1ea45a1337ee">pytorch::Hardtanh::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:810</div></div>
<div class="ttc" id="classpytorch_1_1_branch_html_af70ee99c631a3c21d87ba0460130a437"><div class="ttname"><a href="classpytorch_1_1_branch.html#af70ee99c631a3c21d87ba0460130a437">pytorch::Branch::get_copies</a></div><div class="ttdeci">int get_copies() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:653</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_ae0b8e103f4f37770a9ec0a6c079bc609"><div class="ttname"><a href="classpytorch_1_1_slice3.html#ae0b8e103f4f37770a9ec0a6c079bc609">pytorch::Slice3::dim</a></div><div class="ttdeci">int dim</div><div class="ttdef"><b>Definition:</b> layers.hpp:690</div></div>
<div class="ttc" id="classpytorch_1_1_max_unpool2d_html_a825b92beb3f4120595eb7d1288201802"><div class="ttname"><a href="classpytorch_1_1_max_unpool2d.html#a825b92beb3f4120595eb7d1288201802">pytorch::MaxUnpool2d::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forward pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:306</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_ada48f51ace7479c934b5910fd00ee2ca"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#ada48f51ace7479c934b5910fd00ee2ca">pytorch::BatchNorm2d::running_mean</a></div><div class="ttdeci">af::array running_mean</div><div class="ttdef"><b>Definition:</b> layers.hpp:376</div></div>
<div class="ttc" id="classpytorch_1_1_sigmoid_html"><div class="ttname"><a href="classpytorch_1_1_sigmoid.html">pytorch::Sigmoid</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:779</div></div>
<div class="ttc" id="classpytorch_1_1_layer_html"><div class="ttname"><a href="classpytorch_1_1_layer.html">pytorch::Layer</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:60</div></div>
<div class="ttc" id="classpytorch_1_1_avg_pool2d_html_a6a08e267be98ce762c062052cb9d046b"><div class="ttname"><a href="classpytorch_1_1_avg_pool2d.html#a6a08e267be98ce762c062052cb9d046b">pytorch::AvgPool2d::operator()</a></div><div class="ttdeci">std::vector&lt; af::array &gt; operator()(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Implements the forwards pass. </div><div class="ttdef"><b>Definition:</b> layers.hpp:357</div></div>
<div class="ttc" id="classpytorch_1_1_slice2_html"><div class="ttname"><a href="classpytorch_1_1_slice2.html">pytorch::Slice2</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:667</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a2d4e756090fe5a4c9637ad97959d7614"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a2d4e756090fe5a4c9637ad97959d7614">pytorch::Conv2d::Conv2d</a></div><div class="ttdeci">Conv2d(const conv_params_t &amp;params, const af::array &amp;filters, const af::array &amp;bias)</div><div class="ttdoc">Constructs a Conv2d object given parameters, filters, and bias tensors. </div><div class="ttdef"><b>Definition:</b> layers.hpp:127</div></div>
<div class="ttc" id="classpytorch_1_1_softmax_html"><div class="ttname"><a href="classpytorch_1_1_softmax.html">pytorch::Softmax</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:834</div></div>
<div class="ttc" id="classpytorch_1_1_slice3_html_a53fbbf80acc37d0d12520f583158461e"><div class="ttname"><a href="classpytorch_1_1_slice3.html#a53fbbf80acc37d0d12520f583158461e">pytorch::Slice3::get_dim</a></div><div class="ttdeci">int get_dim() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:694</div></div>
<div class="ttc" id="namespacepytorch_html_aa67d3445f1e6d5b9256f2fef9932d196"><div class="ttname"><a href="namespacepytorch.html#aa67d3445f1e6d5b9256f2fef9932d196">pytorch::dims</a></div><div class="ttdeci">dims</div><div class="ttdoc">Convenience enum to use whenever you need to specify a dimension (like in Concat) ...</div><div class="ttdef"><b>Definition:</b> layers.hpp:44</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a1816381a3443fc87ee9b25efd0cfe6e3"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a1816381a3443fc87ee9b25efd0cfe6e3">pytorch::BatchNorm2d::add_running_var</a></div><div class="ttdeci">void add_running_var(const std::string &amp;running_var_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;running_var_dims={})</div><div class="ttdoc">Adds running_var if it wasn&amp;#39;t added by the constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:486</div></div>
<div class="ttc" id="classpytorch_1_1_concat2_html_ac8da916e9933b1dfcbede7db883cec3f"><div class="ttname"><a href="classpytorch_1_1_concat2.html#ac8da916e9933b1dfcbede7db883cec3f">pytorch::Concat2::dim</a></div><div class="ttdeci">int dim</div><div class="ttdef"><b>Definition:</b> layers.hpp:732</div></div>
<div class="ttc" id="classpytorch_1_1_sigmoid_html_a8e7e598171e919a5dd3dfd54ad38dbdc"><div class="ttname"><a href="classpytorch_1_1_sigmoid.html#a8e7e598171e919a5dd3dfd54ad38dbdc">pytorch::Sigmoid::forward</a></div><div class="ttdeci">std::vector&lt; af::array &gt; forward(const std::vector&lt; af::array &gt; &amp;input)</div><div class="ttdoc">Forward function for this layer. </div><div class="ttdef"><b>Definition:</b> layers.hpp:781</div></div>
<div class="ttc" id="classpytorch_1_1_max_pool2d_html_a5f16e26478688ec83fa6ebc52b463973"><div class="ttname"><a href="classpytorch_1_1_max_pool2d.html#a5f16e26478688ec83fa6ebc52b463973">pytorch::MaxPool2d::get_indices</a></div><div class="ttdeci">af::array get_indices() const</div><div class="ttdef"><b>Definition:</b> layers.hpp:254</div></div>
<div class="ttc" id="namespacepytorch_html_aa1b0dc2ffe07685855199e859712f0a3"><div class="ttname"><a href="namespacepytorch.html#aa1b0dc2ffe07685855199e859712f0a3">pytorch::copy_branch</a></div><div class="ttdeci">std::vector&lt; af::array &gt; copy_branch(const af::array &amp;input, const int &amp;copies)</div><div class="ttdef"><b>Definition:</b> ops.hpp:157</div></div>
<div class="ttc" id="classpytorch_1_1_max_unpool2d_html_a9b1e85a9ead15064ae02813a7432ee76"><div class="ttname"><a href="classpytorch_1_1_max_unpool2d.html#a9b1e85a9ead15064ae02813a7432ee76">pytorch::MaxUnpool2d::params</a></div><div class="ttdeci">pooling_params_t params</div><div class="ttdef"><b>Definition:</b> layers.hpp:289</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_a69aa20f2f1e771bbb4048a682c44a4a7"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#a69aa20f2f1e771bbb4048a682c44a4a7">pytorch::Conv2d::bias</a></div><div class="ttdeci">af::array bias</div><div class="ttdef"><b>Definition:</b> layers.hpp:114</div></div>
<div class="ttc" id="namespacepytorch_html_aacf5782da70434cc8657a5ff4c612fc5"><div class="ttname"><a href="namespacepytorch.html#aacf5782da70434cc8657a5ff4c612fc5">pytorch::maxpool</a></div><div class="ttdeci">af::array maxpool(const pooling_params_t &amp;params, const af::array &amp;input, af::array &amp;indices)</div><div class="ttdef"><b>Definition:</b> ops.hpp:240</div></div>
<div class="ttc" id="classpytorch_1_1_conv2d_html_ac6e2cd68c9a2056e9cb5b5ed643ca057"><div class="ttname"><a href="classpytorch_1_1_conv2d.html#ac6e2cd68c9a2056e9cb5b5ed643ca057">pytorch::Conv2d::has_bias</a></div><div class="ttdeci">bool has_bias</div><div class="ttdef"><b>Definition:</b> layers.hpp:117</div></div>
<div class="ttc" id="ops_8hpp_html"><div class="ttname"><a href="ops_8hpp.html">ops.hpp</a></div><div class="ttdoc">Holds all the implementations of the forward modules. </div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a4db382b11a3f91778797a6e940692d86"><div class="ttname"><a href="classpytorch_1_1_linear.html#a4db382b11a3f91778797a6e940692d86">pytorch::Linear::add_bias</a></div><div class="ttdeci">void add_bias(const std::string &amp;bias_filename, const std::vector&lt; int &gt; &amp;bias_dims)</div><div class="ttdoc">Read in bias from a file given here if it wasn&amp;#39;t passed to the constructor. Overwrites current conten...</div><div class="ttdef"><b>Definition:</b> layers.hpp:602</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a1ce5755565afc4f3de332e3f6836f3bd"><div class="ttname"><a href="classpytorch_1_1_linear.html#a1ce5755565afc4f3de332e3f6836f3bd">pytorch::Linear::weights</a></div><div class="ttdeci">af::array weights</div><div class="ttdef"><b>Definition:</b> layers.hpp:526</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_af29892810fccc85d2bc202c16c5d49fe"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#af29892810fccc85d2bc202c16c5d49fe">pytorch::BatchNorm2d::add_gamma</a></div><div class="ttdeci">void add_gamma(const std::string &amp;gamma_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;gamma_dims={})</div><div class="ttdoc">Adds gamma to the layer if the name wasn&amp;#39;t passed to the constructor. </div><div class="ttdef"><b>Definition:</b> layers.hpp:444</div></div>
<div class="ttc" id="classpytorch_1_1_concat3_html"><div class="ttname"><a href="classpytorch_1_1_concat3.html">pytorch::Concat3</a></div><div class="ttdef"><b>Definition:</b> layers.hpp:747</div></div>
<div class="ttc" id="classpytorch_1_1_batch_norm2d_html_a910802963973f5d64fb6d281635a1035"><div class="ttname"><a href="classpytorch_1_1_batch_norm2d.html#a910802963973f5d64fb6d281635a1035">pytorch::BatchNorm2d::BatchNorm2d</a></div><div class="ttdeci">BatchNorm2d(const std::string &amp;gamma_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;gamma_dims={}, const std::string &amp;beta_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;beta_dims={}, const std::string &amp;running_mean_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;running_mean_dims={}, const std::string &amp;running_var_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;running_var_dims={}, const float &amp;epsilon=1e-5, const std::string &amp;python_home=&quot;../scripts&quot;)</div><div class="ttdoc">Constructs a BatchNorm2d object and loads the requisite tensors in from filenames and sizes...</div><div class="ttdef"><b>Definition:</b> layers.hpp:412</div></div>
<div class="ttc" id="namespacepytorch_html_a9243e92d218fdf3718ab963e4005988e"><div class="ttname"><a href="namespacepytorch.html#a9243e92d218fdf3718ab963e4005988e">pytorch::cat3</a></div><div class="ttdeci">af::array cat3(const af::array &amp;input1, const af::array &amp;input2, const af::array &amp;input3, const int &amp;dim)</div><div class="ttdef"><b>Definition:</b> ops.hpp:206</div></div>
<div class="ttc" id="classpytorch_1_1_linear_html_a47740884c0ce199daecd9958bd6b6ca3"><div class="ttname"><a href="classpytorch_1_1_linear.html#a47740884c0ce199daecd9958bd6b6ca3">pytorch::Linear::Linear</a></div><div class="ttdeci">Linear(const af::array &amp;weights, const af::array &amp;bias)</div><div class="ttdoc">Constructs a Linear object given weights, and bias tensors. </div><div class="ttdef"><b>Definition:</b> layers.hpp:538</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="layers_8hpp.html">layers.hpp</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
